{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hands-on: Training and deploying GluonNLP models on AWS SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will learn the following:\n",
    "\n",
    "- practice fine-tuning BERT for sentiment classification\n",
    "- exporting models in a self-contained way\n",
    "- creating a SageMaker Endpoint serving your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras-mxnet                        2.2.4.2       \n",
      "mxnet-cu101                        1.6.0b20191122\n",
      "mxnet-model-server                 1.0.5         \n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "gluonnlp                           0.9.0.dev0    \n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# this notebook requires mxnet-cu101 >= 1.6.0b20191102, gluonnlp >= 0.8.1\n",
    "# you can create a sagemaker notebook instance with the lifecycle configuration file: sagemaker-lifecycle.config\n",
    "!pip list | grep mxnet\n",
    "!pip list | grep gluonnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import argparse, time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "# Hyperparameters\n",
    "parser = argparse.ArgumentParser('BERT finetuning')\n",
    "parser.add_argument('--batch_size', default=32)\n",
    "parser.add_argument('--num_epochs', default=1)\n",
    "parser.add_argument('--lr', default=5e-5)\n",
    "args = parser.parse_args([])\n",
    "\n",
    "batch_size = args.batch_size\n",
    "num_epochs = args.num_epochs\n",
    "lr = args.lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Get Pre-trained BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can load the pre-trained BERT easily using the model API in GluonNLP, which returns the vocabulary along with the model. We include the pooler layer of the pre-trained model by setting `use_pooler` to `True`.\n",
    "The list of pre-trained BERT models available in GluonNLP can be found [here](http://gluon-nlp.mxnet.io/model_zoo/bert/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:44:54.906532Z",
     "start_time": "2019-07-26T22:44:34.102308Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ctx = mx.gpu(0)\n",
    "bert, vocabulary = nlp.model.get_model('bert_12_768_12', # the 12-layer BERT Base model\n",
    "                                        dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                        # use pre-trained weights\n",
    "                                        pretrained=True, ctx=ctx,\n",
    "                                        # decoder and classifier are for pre-training only\n",
    "                                        use_decoder=False, use_classifier=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now that we have loaded the BERT model, we only need to attach an additional layer for classification.\n",
    "The `BERTClassifier` class uses a BERT base model to encode sentence representation, followed by a `nn.Dense` layer for classification. We only need to initialize the classification layer. The encoding layers are already initialized with pre-trained weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "net = nlp.model.BERTClassifier(bert, num_classes=2)\n",
    "net.classifier.initialize(ctx=ctx)  # only initialize the classification layer from scratch\n",
    "net.hybridize()  # compile the model, required for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To use the pre-trained BERT model, we need to:\n",
    "- tokenize the inputs into words,\n",
    "- insert [CLS] at the beginning of a sentence, \n",
    "- insert [SEP] at the end of a sentence, and\n",
    "- generate segment ids\n",
    "\n",
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We again use the IMDB dataset, but for this time, downloading using the GluonNLP data API. We then use the transform API to transform the raw scores to positive labels and negative labels. \n",
    "To process sentences with BERT-style '[CLS]', '[SEP]' tokens, you can use `data.BERTSentenceTransform` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:44:57.188028Z",
     "start_time": "2019-07-26T22:44:57.181395Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_raw = nlp.data.IMDB('train')\n",
    "test_dataset_raw = nlp.data.IMDB('test')\n",
    "\n",
    "# tokenize texts into words\n",
    "tokenizer = nlp.data.BERTTokenizer(vocabulary)\n",
    "# add begin-of-sentence, end-of-sentence tokens and perform vocabulary lookup\n",
    "transform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length=128, pair=False, pad=False)\n",
    "\n",
    "def transform_fn(data):\n",
    "    # transform texts to tensors\n",
    "    text, label = data\n",
    "    # transform label into position / negative\n",
    "    label = 1 if label >= 5 else 0\n",
    "    data, length, segment_type = transform([text])\n",
    "    return data.astype('float32'), length.astype('float32'), segment_type.astype('float32'), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T22:44:57.197310Z",
     "start_time": "2019-07-26T22:44:57.189448Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "16"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence = \n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n",
      "\n",
      "word indices = \n",
      "[    2 22953  2213  4381  2152  2003  1037  9476  4038  1012  2009  2743\n",
      "  2012  1996  2168  2051  2004  2070  2060  3454  2055  2082  2166  1010\n",
      "  2107  2004  1000  5089  1000  1012  2026  3486  2086  1999  1996  4252\n",
      "  9518  2599  2033  2000  2903  2008 22953  2213  4381  2152  1005  1055\n",
      " 18312  2003  2172  3553  2000  4507  2084  2003  1000  5089  1000  1012\n",
      "  1996 25740  2000  5788 13732  1010  1996 12369  3993  2493  2040  2064\n",
      "  2156  2157  2083  2037 17203  5089  1005 13433  8737  1010  1996  9004\n",
      " 10196  4757  1997  1996  2878  3663  1010  2035 10825  2033  1997  1996\n",
      "  2816  1045  2354  1998  2037  2493  1012  2043  1045  2387  1996  2792\n",
      "  1999  2029  1037  3076  8385  2699  2000  6402  2091  1996  2082  1010\n",
      "  1045  3202  7383  1012  1012  1012  1012     3]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset_raw.transform(transform_fn)\n",
    "test_dataset = test_dataset_raw.transform(transform_fn)\n",
    "\n",
    "data, length, _, label = train_dataset[0]\n",
    "print('original sentence = \\n{}'.format(train_dataset_raw[0][0]))\n",
    "print('\\nword indices = \\n{}'.format(data.astype('int32')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now we have all the pieces to put together, and we can finally start fine-tuning the\n",
    "model with a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "padding_id = vocabulary[vocabulary.padding_token]\n",
    "batchify_fn = nlp.data.batchify.Tuple(\n",
    "        nlp.data.batchify.Pad(axis=0, pad_val=padding_id), # words\n",
    "        nlp.data.batchify.Stack(), # valid length\n",
    "        nlp.data.batchify.Pad(axis=0, pad_val=0), # segment type\n",
    "        nlp.data.batchify.Stack(np.float32)) # label\n",
    "\n",
    "train_data = mx.gluon.data.DataLoader(train_dataset,\n",
    "                               batchify_fn=batchify_fn, shuffle=True,\n",
    "                               batch_size=batch_size, num_workers=4)\n",
    "test_data = mx.gluon.data.DataLoader(test_dataset,\n",
    "                              batchify_fn=batchify_fn,\n",
    "                              shuffle=False, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.contrib.estimator import TrainBegin, BatchBegin, LoggingHandler\n",
    "\n",
    "\n",
    "class MyLearningRateHandler(TrainBegin, BatchBegin):\n",
    "    \"\"\"Warm-up learning rate handler.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trainer: gluon.Trainer\n",
    "        Trainer object to adjust the learning rate on.\n",
    "    num_warmup_steps: int\n",
    "        Number of initial steps during which the learning rate is linearly\n",
    "        increased to it's target.\n",
    "    num_train_steps: int\n",
    "        Total number of steps to be taken during training. Should be equal to\n",
    "        the number of batches * number of epochs.\n",
    "    lr: float\n",
    "        Base learning rate to reach after warmup.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, trainer, num_warmup_steps, num_train_steps, lr):\n",
    "        self.trainer = trainer\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        self.num_train_steps = num_train_steps\n",
    "        self.lr = lr\n",
    "\n",
    "        self.step_num = 0\n",
    "\n",
    "    def train_begin(self, estimator, *args, **kwargs):\n",
    "        self.step_num = 0\n",
    "\n",
    "    def batch_begin(self, estimator, *args, **kwargs):\n",
    "        self.step_num += 1\n",
    "        if self.step_num < self.num_warmup_steps:\n",
    "            new_lr = self.lr * self.step_num / self.num_warmup_steps\n",
    "        else:\n",
    "            non_warmup_steps = self.step_num - self.num_warmup_steps\n",
    "            offset = non_warmup_steps / (self.num_train_steps - self.num_warmup_steps)\n",
    "            new_lr = self.lr - offset * self.lr\n",
    "        self.trainer.set_learning_rate(new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.contrib import estimator\n",
    "from mxnet.gluon.utils import split_and_load\n",
    "\n",
    "class MyEstimator(estimator.Estimator):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # params for grad clipping\n",
    "        self.params = [p for p in self.net.collect_params().values() if p.grad_req != 'null']\n",
    "        \n",
    "    def fit_batch(self, train_batch, batch_axis=0):\n",
    "        train_batch = [split_and_load(x, ctx_list=self.context, batch_axis=batch_axis) for x in train_batch]\n",
    "        with mx.autograd.record():\n",
    "            pred = [self.net(inp, token_type, seq_len) for inp, seq_len, token_type, _ in zip(*train_batch)]\n",
    "            loss = [self.loss(out, label.astype('float32')) for out, _, _, _, label in zip(pred, *train_batch)]\n",
    "        mx.autograd.backward(loss)\n",
    "\n",
    "        # Gradient clipping\n",
    "        trainer.allreduce_grads()\n",
    "        nlp.utils.clip_grad_global_norm(self.params, 1)\n",
    "        trainer.update(1)\n",
    "\n",
    "        return train_batch[:3], train_batch[3], pred, loss\n",
    "\n",
    "    def evaluate_batch(self, val_batch, val_metrics, batch_axis=0):\n",
    "        val_batch = [split_and_load(x, ctx_list=self.context, batch_axis=batch_axis) for x in val_batch]\n",
    "        pred = [self.net(inp, token_type, seq_len) for inp, seq_len, token_type, _ in zip(*val_batch)]\n",
    "        label = [l for _, _, _, l in zip(*val_batch)]\n",
    "        # update metrics\n",
    "        for metric in val_metrics:\n",
    "            metric.update(label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begin: using optimizer BERTAdam with current learning rate 0.0001 \n",
      "Train for 1 epochs.\n",
      "[Epoch 0] Begin, current learning rate: 0.0001\n",
      "[Epoch 0][Batch 0][Samples 32] time/batch: 4.138s training loss: 0.7866, training accuracy: 0.4062\n",
      "[Epoch 0][Batch 1][Samples 64] time/batch: 0.277s training loss: 0.7901, training accuracy: 0.4062\n",
      "[Epoch 0][Batch 2][Samples 96] time/batch: 0.265s training loss: 0.7752, training accuracy: 0.4167\n",
      "[Epoch 0][Batch 3][Samples 128] time/batch: 0.254s training loss: 0.7569, training accuracy: 0.4531\n",
      "[Epoch 0][Batch 4][Samples 160] time/batch: 0.261s training loss: 0.7446, training accuracy: 0.4625\n",
      "[Epoch 0][Batch 5][Samples 192] time/batch: 0.256s training loss: 0.7480, training accuracy: 0.4167\n",
      "[Epoch 0][Batch 6][Samples 224] time/batch: 0.264s training loss: 0.7369, training accuracy: 0.4375\n",
      "[Epoch 0][Batch 7][Samples 256] time/batch: 0.254s training loss: 0.7301, training accuracy: 0.4531\n",
      "[Epoch 0][Batch 8][Samples 288] time/batch: 0.270s training loss: 0.7246, training accuracy: 0.4583\n",
      "[Epoch 0][Batch 9][Samples 320] time/batch: 0.256s training loss: 0.7206, training accuracy: 0.4594\n",
      "[Epoch 0][Batch 10][Samples 352] time/batch: 0.254s training loss: 0.7173, training accuracy: 0.4716\n",
      "[Epoch 0][Batch 11][Samples 384] time/batch: 0.259s training loss: 0.7153, training accuracy: 0.4714\n",
      "[Epoch 0][Batch 12][Samples 416] time/batch: 0.263s training loss: 0.7143, training accuracy: 0.4760\n",
      "[Epoch 0][Batch 13][Samples 448] time/batch: 0.266s training loss: 0.7128, training accuracy: 0.4844\n",
      "[Epoch 0][Batch 14][Samples 480] time/batch: 0.255s training loss: 0.7126, training accuracy: 0.4833\n",
      "[Epoch 0][Batch 15][Samples 512] time/batch: 0.256s training loss: 0.7112, training accuracy: 0.4805\n",
      "[Epoch 0][Batch 16][Samples 544] time/batch: 0.253s training loss: 0.7073, training accuracy: 0.4963\n",
      "[Epoch 0][Batch 17][Samples 576] time/batch: 0.257s training loss: 0.7038, training accuracy: 0.5000\n",
      "[Epoch 0][Batch 18][Samples 608] time/batch: 0.259s training loss: 0.7006, training accuracy: 0.5049\n",
      "[Epoch 0][Batch 19][Samples 640] time/batch: 0.254s training loss: 0.6932, training accuracy: 0.5172\n",
      "[Epoch 0][Batch 20][Samples 672] time/batch: 0.253s training loss: 0.6866, training accuracy: 0.5268\n",
      "[Epoch 0][Batch 21][Samples 704] time/batch: 0.256s training loss: 0.6786, training accuracy: 0.5384\n",
      "[Epoch 0][Batch 22][Samples 736] time/batch: 0.254s training loss: 0.6785, training accuracy: 0.5435\n",
      "[Epoch 0][Batch 23][Samples 768] time/batch: 0.254s training loss: 0.6710, training accuracy: 0.5508\n",
      "[Epoch 0][Batch 24][Samples 800] time/batch: 0.255s training loss: 0.6749, training accuracy: 0.5525\n",
      "[Epoch 0][Batch 25][Samples 832] time/batch: 0.257s training loss: 0.6741, training accuracy: 0.5565\n",
      "[Epoch 0][Batch 26][Samples 864] time/batch: 0.256s training loss: 0.6628, training accuracy: 0.5660\n",
      "[Epoch 0][Batch 27][Samples 896] time/batch: 0.254s training loss: 0.6505, training accuracy: 0.5759\n",
      "[Epoch 0][Batch 28][Samples 928] time/batch: 0.267s training loss: 0.6456, training accuracy: 0.5819\n",
      "[Epoch 0][Batch 29][Samples 960] time/batch: 0.255s training loss: 0.6460, training accuracy: 0.5833\n",
      "[Epoch 0][Batch 30][Samples 992] time/batch: 0.256s training loss: 0.6476, training accuracy: 0.5867\n",
      "[Epoch 0][Batch 31][Samples 1024] time/batch: 0.256s training loss: 0.6506, training accuracy: 0.5918\n",
      "[Epoch 0][Batch 32][Samples 1056] time/batch: 0.266s training loss: 0.6453, training accuracy: 0.5985\n",
      "[Epoch 0][Batch 33][Samples 1088] time/batch: 0.259s training loss: 0.6371, training accuracy: 0.6066\n",
      "[Epoch 0][Batch 34][Samples 1120] time/batch: 0.270s training loss: 0.6274, training accuracy: 0.6161\n",
      "[Epoch 0][Batch 35][Samples 1152] time/batch: 0.260s training loss: 0.6216, training accuracy: 0.6207\n",
      "[Epoch 0][Batch 36][Samples 1184] time/batch: 0.255s training loss: 0.6292, training accuracy: 0.6208\n",
      "[Epoch 0][Batch 37][Samples 1216] time/batch: 0.254s training loss: 0.6351, training accuracy: 0.6234\n",
      "[Epoch 0][Batch 38][Samples 1248] time/batch: 0.258s training loss: 0.6334, training accuracy: 0.6266\n",
      "[Epoch 0][Batch 39][Samples 1280] time/batch: 0.258s training loss: 0.6330, training accuracy: 0.6289\n",
      "[Epoch 0][Batch 40][Samples 1312] time/batch: 0.255s training loss: 0.6314, training accuracy: 0.6326\n",
      "[Epoch 0][Batch 41][Samples 1344] time/batch: 0.258s training loss: 0.6303, training accuracy: 0.6369\n",
      "[Epoch 0][Batch 42][Samples 1376] time/batch: 0.254s training loss: 0.6293, training accuracy: 0.6388\n",
      "[Epoch 0][Batch 43][Samples 1408] time/batch: 0.258s training loss: 0.6263, training accuracy: 0.6435\n",
      "[Epoch 0][Batch 44][Samples 1440] time/batch: 0.260s training loss: 0.6241, training accuracy: 0.6451\n",
      "[Epoch 0][Batch 45][Samples 1472] time/batch: 0.263s training loss: 0.6269, training accuracy: 0.6420\n",
      "[Epoch 0][Batch 46][Samples 1504] time/batch: 0.259s training loss: 0.6238, training accuracy: 0.6443\n",
      "[Epoch 0][Batch 47][Samples 1536] time/batch: 0.254s training loss: 0.6184, training accuracy: 0.6491\n",
      "[Epoch 0][Batch 48][Samples 1568] time/batch: 0.264s training loss: 0.6155, training accuracy: 0.6518\n",
      "[Epoch 0][Batch 49][Samples 1600] time/batch: 0.265s training loss: 0.6116, training accuracy: 0.6550\n",
      "[Epoch 0][Batch 50][Samples 1632] time/batch: 0.263s training loss: 0.6149, training accuracy: 0.6556\n",
      "[Epoch 0][Batch 51][Samples 1664] time/batch: 0.267s training loss: 0.6103, training accuracy: 0.6587\n",
      "[Epoch 0][Batch 52][Samples 1696] time/batch: 0.255s training loss: 0.6087, training accuracy: 0.6610\n",
      "[Epoch 0][Batch 53][Samples 1728] time/batch: 0.271s training loss: 0.6067, training accuracy: 0.6632\n",
      "[Epoch 0][Batch 54][Samples 1760] time/batch: 0.254s training loss: 0.6028, training accuracy: 0.6659\n",
      "[Epoch 0][Batch 55][Samples 1792] time/batch: 0.255s training loss: 0.6021, training accuracy: 0.6669\n",
      "[Epoch 0][Batch 56][Samples 1824] time/batch: 0.256s training loss: 0.5986, training accuracy: 0.6700\n",
      "[Epoch 0][Batch 57][Samples 1856] time/batch: 0.261s training loss: 0.5971, training accuracy: 0.6713\n",
      "[Epoch 0][Batch 58][Samples 1888] time/batch: 0.255s training loss: 0.5951, training accuracy: 0.6732\n",
      "[Epoch 0][Batch 59][Samples 1920] time/batch: 0.260s training loss: 0.5919, training accuracy: 0.6755\n",
      "[Epoch 0][Batch 60][Samples 1952] time/batch: 0.267s training loss: 0.5883, training accuracy: 0.6783\n",
      "[Epoch 0][Batch 61][Samples 1984] time/batch: 0.258s training loss: 0.5860, training accuracy: 0.6799\n",
      "[Epoch 0][Batch 62][Samples 2016] time/batch: 0.256s training loss: 0.5830, training accuracy: 0.6820\n",
      "[Epoch 0][Batch 63][Samples 2048] time/batch: 0.255s training loss: 0.5816, training accuracy: 0.6836\n",
      "[Epoch 0][Batch 64][Samples 2080] time/batch: 0.261s training loss: 0.5815, training accuracy: 0.6837\n",
      "[Epoch 0][Batch 65][Samples 2112] time/batch: 0.257s training loss: 0.5754, training accuracy: 0.6875\n",
      "[Epoch 0][Batch 66][Samples 2144] time/batch: 0.258s training loss: 0.5734, training accuracy: 0.6884\n",
      "[Epoch 0][Batch 67][Samples 2176] time/batch: 0.256s training loss: 0.5704, training accuracy: 0.6907\n",
      "[Epoch 0][Batch 68][Samples 2208] time/batch: 0.262s training loss: 0.5757, training accuracy: 0.6907\n",
      "[Epoch 0][Batch 69][Samples 2240] time/batch: 0.266s training loss: 0.5749, training accuracy: 0.6911\n",
      "[Epoch 0][Batch 70][Samples 2272] time/batch: 0.252s training loss: 0.5747, training accuracy: 0.6919\n",
      "[Epoch 0][Batch 71][Samples 2304] time/batch: 0.260s training loss: 0.5724, training accuracy: 0.6940\n",
      "[Epoch 0][Batch 72][Samples 2336] time/batch: 0.255s training loss: 0.5722, training accuracy: 0.6943\n",
      "[Epoch 0][Batch 73][Samples 2368] time/batch: 0.259s training loss: 0.5751, training accuracy: 0.6934\n",
      "[Epoch 0][Batch 74][Samples 2400] time/batch: 0.266s training loss: 0.5773, training accuracy: 0.6925\n",
      "[Epoch 0][Batch 75][Samples 2432] time/batch: 0.259s training loss: 0.5759, training accuracy: 0.6945\n",
      "[Epoch 0][Batch 76][Samples 2464] time/batch: 0.266s training loss: 0.5753, training accuracy: 0.6944\n",
      "[Epoch 0][Batch 77][Samples 2496] time/batch: 0.268s training loss: 0.5733, training accuracy: 0.6963\n",
      "[Epoch 0][Batch 78][Samples 2528] time/batch: 0.255s training loss: 0.5706, training accuracy: 0.6990\n",
      "[Epoch 0][Batch 79][Samples 2560] time/batch: 0.258s training loss: 0.5679, training accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 80][Samples 2592] time/batch: 0.264s training loss: 0.5644, training accuracy: 0.7022\n",
      "[Epoch 0][Batch 81][Samples 2624] time/batch: 0.258s training loss: 0.5633, training accuracy: 0.7031\n",
      "[Epoch 0][Batch 82][Samples 2656] time/batch: 0.253s training loss: 0.5606, training accuracy: 0.7048\n",
      "[Epoch 0][Batch 83][Samples 2688] time/batch: 0.270s training loss: 0.5606, training accuracy: 0.7057\n",
      "[Epoch 0][Batch 84][Samples 2720] time/batch: 0.252s training loss: 0.5587, training accuracy: 0.7074\n",
      "[Epoch 0][Batch 85][Samples 2752] time/batch: 0.262s training loss: 0.5600, training accuracy: 0.7082\n",
      "[Epoch 0][Batch 86][Samples 2784] time/batch: 0.267s training loss: 0.5579, training accuracy: 0.7101\n",
      "[Epoch 0][Batch 87][Samples 2816] time/batch: 0.265s training loss: 0.5571, training accuracy: 0.7113\n",
      "[Epoch 0][Batch 88][Samples 2848] time/batch: 0.259s training loss: 0.5572, training accuracy: 0.7117\n",
      "[Epoch 0][Batch 89][Samples 2880] time/batch: 0.254s training loss: 0.5550, training accuracy: 0.7135\n",
      "[Epoch 0][Batch 90][Samples 2912] time/batch: 0.257s training loss: 0.5521, training accuracy: 0.7160\n",
      "[Epoch 0][Batch 91][Samples 2944] time/batch: 0.257s training loss: 0.5501, training accuracy: 0.7174\n",
      "[Epoch 0][Batch 92][Samples 2976] time/batch: 0.255s training loss: 0.5493, training accuracy: 0.7184\n",
      "[Epoch 0][Batch 93][Samples 3008] time/batch: 0.254s training loss: 0.5479, training accuracy: 0.7197\n",
      "[Epoch 0][Batch 94][Samples 3040] time/batch: 0.258s training loss: 0.5451, training accuracy: 0.7217\n",
      "[Epoch 0][Batch 95][Samples 3072] time/batch: 0.254s training loss: 0.5440, training accuracy: 0.7230\n",
      "[Epoch 0][Batch 96][Samples 3104] time/batch: 0.258s training loss: 0.5451, training accuracy: 0.7233\n",
      "[Epoch 0][Batch 97][Samples 3136] time/batch: 0.256s training loss: 0.5431, training accuracy: 0.7245\n",
      "[Epoch 0][Batch 98][Samples 3168] time/batch: 0.268s training loss: 0.5443, training accuracy: 0.7247\n",
      "[Epoch 0][Batch 99][Samples 3200] time/batch: 0.255s training loss: 0.5411, training accuracy: 0.7269\n",
      "[Epoch 0][Batch 100][Samples 3232] time/batch: 0.264s training loss: 0.5412, training accuracy: 0.7277\n",
      "[Epoch 0][Batch 101][Samples 3264] time/batch: 0.254s training loss: 0.5408, training accuracy: 0.7279\n",
      "[Epoch 0][Batch 102][Samples 3296] time/batch: 0.259s training loss: 0.5387, training accuracy: 0.7291\n",
      "[Epoch 0][Batch 103][Samples 3328] time/batch: 0.254s training loss: 0.5379, training accuracy: 0.7302\n",
      "[Epoch 0][Batch 104][Samples 3360] time/batch: 0.263s training loss: 0.5350, training accuracy: 0.7321\n",
      "[Epoch 0][Batch 105][Samples 3392] time/batch: 0.264s training loss: 0.5344, training accuracy: 0.7326\n",
      "[Epoch 0][Batch 106][Samples 3424] time/batch: 0.259s training loss: 0.5327, training accuracy: 0.7339\n",
      "[Epoch 0][Batch 107][Samples 3456] time/batch: 0.256s training loss: 0.5320, training accuracy: 0.7347\n",
      "[Epoch 0][Batch 108][Samples 3488] time/batch: 0.259s training loss: 0.5289, training accuracy: 0.7368\n",
      "[Epoch 0][Batch 109][Samples 3520] time/batch: 0.256s training loss: 0.5277, training accuracy: 0.7378\n",
      "[Epoch 0][Batch 110][Samples 3552] time/batch: 0.274s training loss: 0.5266, training accuracy: 0.7385\n",
      "[Epoch 0][Batch 111][Samples 3584] time/batch: 0.264s training loss: 0.5262, training accuracy: 0.7388\n",
      "[Epoch 0][Batch 112][Samples 3616] time/batch: 0.269s training loss: 0.5235, training accuracy: 0.7406\n",
      "[Epoch 0][Batch 113][Samples 3648] time/batch: 0.264s training loss: 0.5214, training accuracy: 0.7418\n",
      "[Epoch 0][Batch 114][Samples 3680] time/batch: 0.273s training loss: 0.5198, training accuracy: 0.7429\n",
      "[Epoch 0][Batch 115][Samples 3712] time/batch: 0.309s training loss: 0.5187, training accuracy: 0.7441\n",
      "[Epoch 0][Batch 116][Samples 3744] time/batch: 0.261s training loss: 0.5185, training accuracy: 0.7441\n",
      "[Epoch 0][Batch 117][Samples 3776] time/batch: 0.266s training loss: 0.5202, training accuracy: 0.7439\n",
      "[Epoch 0][Batch 118][Samples 3808] time/batch: 0.264s training loss: 0.5209, training accuracy: 0.7432\n",
      "[Epoch 0][Batch 119][Samples 3840] time/batch: 0.259s training loss: 0.5192, training accuracy: 0.7440\n",
      "[Epoch 0][Batch 120][Samples 3872] time/batch: 0.257s training loss: 0.5169, training accuracy: 0.7451\n",
      "[Epoch 0][Batch 121][Samples 3904] time/batch: 0.266s training loss: 0.5170, training accuracy: 0.7451\n",
      "[Epoch 0][Batch 122][Samples 3936] time/batch: 0.255s training loss: 0.5164, training accuracy: 0.7452\n",
      "[Epoch 0][Batch 123][Samples 3968] time/batch: 0.268s training loss: 0.5155, training accuracy: 0.7460\n",
      "[Epoch 0][Batch 124][Samples 4000] time/batch: 0.263s training loss: 0.5155, training accuracy: 0.7462\n",
      "[Epoch 0][Batch 125][Samples 4032] time/batch: 0.256s training loss: 0.5149, training accuracy: 0.7463\n",
      "[Epoch 0][Batch 126][Samples 4064] time/batch: 0.252s training loss: 0.5147, training accuracy: 0.7458\n",
      "[Epoch 0][Batch 127][Samples 4096] time/batch: 0.254s training loss: 0.5143, training accuracy: 0.7468\n",
      "[Epoch 0][Batch 128][Samples 4128] time/batch: 0.265s training loss: 0.5138, training accuracy: 0.7476\n",
      "[Epoch 0][Batch 129][Samples 4160] time/batch: 0.264s training loss: 0.5122, training accuracy: 0.7486\n",
      "[Epoch 0][Batch 130][Samples 4192] time/batch: 0.257s training loss: 0.5108, training accuracy: 0.7493\n",
      "[Epoch 0][Batch 131][Samples 4224] time/batch: 0.258s training loss: 0.5099, training accuracy: 0.7500\n",
      "[Epoch 0][Batch 132][Samples 4256] time/batch: 0.254s training loss: 0.5088, training accuracy: 0.7509\n",
      "[Epoch 0][Batch 133][Samples 4288] time/batch: 0.256s training loss: 0.5072, training accuracy: 0.7519\n",
      "[Epoch 0][Batch 134][Samples 4320] time/batch: 0.263s training loss: 0.5082, training accuracy: 0.7521\n",
      "[Epoch 0][Batch 135][Samples 4352] time/batch: 0.256s training loss: 0.5075, training accuracy: 0.7530\n",
      "[Epoch 0][Batch 136][Samples 4384] time/batch: 0.259s training loss: 0.5059, training accuracy: 0.7536\n",
      "[Epoch 0][Batch 137][Samples 4416] time/batch: 0.256s training loss: 0.5048, training accuracy: 0.7545\n",
      "[Epoch 0][Batch 138][Samples 4448] time/batch: 0.261s training loss: 0.5034, training accuracy: 0.7552\n",
      "[Epoch 0][Batch 139][Samples 4480] time/batch: 0.255s training loss: 0.5030, training accuracy: 0.7554\n",
      "[Epoch 0][Batch 140][Samples 4512] time/batch: 0.268s training loss: 0.5012, training accuracy: 0.7566\n",
      "[Epoch 0][Batch 141][Samples 4544] time/batch: 0.266s training loss: 0.5011, training accuracy: 0.7568\n",
      "[Epoch 0][Batch 142][Samples 4576] time/batch: 0.266s training loss: 0.5019, training accuracy: 0.7563\n",
      "[Epoch 0][Batch 143][Samples 4608] time/batch: 0.256s training loss: 0.5008, training accuracy: 0.7567\n",
      "[Epoch 0][Batch 144][Samples 4640] time/batch: 0.265s training loss: 0.5001, training accuracy: 0.7569\n",
      "[Epoch 0][Batch 145][Samples 4672] time/batch: 0.271s training loss: 0.4997, training accuracy: 0.7575\n",
      "[Epoch 0][Batch 146][Samples 4704] time/batch: 0.258s training loss: 0.4991, training accuracy: 0.7579\n",
      "[Epoch 0][Batch 147][Samples 4736] time/batch: 0.259s training loss: 0.4984, training accuracy: 0.7582\n",
      "[Epoch 0][Batch 148][Samples 4768] time/batch: 0.255s training loss: 0.4977, training accuracy: 0.7588\n",
      "[Epoch 0][Batch 149][Samples 4800] time/batch: 0.255s training loss: 0.4976, training accuracy: 0.7590\n",
      "[Epoch 0][Batch 150][Samples 4832] time/batch: 0.259s training loss: 0.4959, training accuracy: 0.7606\n",
      "[Epoch 0][Batch 151][Samples 4864] time/batch: 0.260s training loss: 0.4955, training accuracy: 0.7605\n",
      "[Epoch 0][Batch 152][Samples 4896] time/batch: 0.258s training loss: 0.4954, training accuracy: 0.7612\n",
      "[Epoch 0][Batch 153][Samples 4928] time/batch: 0.271s training loss: 0.4942, training accuracy: 0.7622\n",
      "[Epoch 0][Batch 154][Samples 4960] time/batch: 0.258s training loss: 0.4926, training accuracy: 0.7631\n",
      "[Epoch 0][Batch 155][Samples 4992] time/batch: 0.255s training loss: 0.4917, training accuracy: 0.7634\n",
      "[Epoch 0][Batch 156][Samples 5024] time/batch: 0.258s training loss: 0.4898, training accuracy: 0.7643\n",
      "[Epoch 0][Batch 157][Samples 5056] time/batch: 0.256s training loss: 0.4901, training accuracy: 0.7646\n",
      "[Epoch 0][Batch 158][Samples 5088] time/batch: 0.261s training loss: 0.4885, training accuracy: 0.7655\n",
      "[Epoch 0][Batch 159][Samples 5120] time/batch: 0.266s training loss: 0.4886, training accuracy: 0.7654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 160][Samples 5152] time/batch: 0.257s training loss: 0.4869, training accuracy: 0.7663\n",
      "[Epoch 0][Batch 161][Samples 5184] time/batch: 0.264s training loss: 0.4866, training accuracy: 0.7662\n",
      "[Epoch 0][Batch 162][Samples 5216] time/batch: 0.269s training loss: 0.4873, training accuracy: 0.7659\n",
      "[Epoch 0][Batch 163][Samples 5248] time/batch: 0.257s training loss: 0.4873, training accuracy: 0.7656\n",
      "[Epoch 0][Batch 164][Samples 5280] time/batch: 0.260s training loss: 0.4864, training accuracy: 0.7657\n",
      "[Epoch 0][Batch 165][Samples 5312] time/batch: 0.254s training loss: 0.4872, training accuracy: 0.7654\n",
      "[Epoch 0][Batch 166][Samples 5344] time/batch: 0.256s training loss: 0.4873, training accuracy: 0.7657\n",
      "[Epoch 0][Batch 167][Samples 5376] time/batch: 0.255s training loss: 0.4858, training accuracy: 0.7666\n",
      "[Epoch 0][Batch 168][Samples 5408] time/batch: 0.259s training loss: 0.4853, training accuracy: 0.7666\n",
      "[Epoch 0][Batch 169][Samples 5440] time/batch: 0.254s training loss: 0.4855, training accuracy: 0.7665\n",
      "[Epoch 0][Batch 170][Samples 5472] time/batch: 0.271s training loss: 0.4843, training accuracy: 0.7670\n",
      "[Epoch 0][Batch 171][Samples 5504] time/batch: 0.268s training loss: 0.4831, training accuracy: 0.7678\n",
      "[Epoch 0][Batch 172][Samples 5536] time/batch: 0.260s training loss: 0.4833, training accuracy: 0.7681\n",
      "[Epoch 0][Batch 173][Samples 5568] time/batch: 0.258s training loss: 0.4831, training accuracy: 0.7681\n",
      "[Epoch 0][Batch 174][Samples 5600] time/batch: 0.257s training loss: 0.4816, training accuracy: 0.7688\n",
      "[Epoch 0][Batch 175][Samples 5632] time/batch: 0.261s training loss: 0.4806, training accuracy: 0.7695\n",
      "[Epoch 0][Batch 176][Samples 5664] time/batch: 0.256s training loss: 0.4807, training accuracy: 0.7698\n",
      "[Epoch 0][Batch 177][Samples 5696] time/batch: 0.261s training loss: 0.4796, training accuracy: 0.7705\n",
      "[Epoch 0][Batch 178][Samples 5728] time/batch: 0.256s training loss: 0.4803, training accuracy: 0.7703\n",
      "[Epoch 0][Batch 179][Samples 5760] time/batch: 0.256s training loss: 0.4794, training accuracy: 0.7710\n",
      "[Epoch 0][Batch 180][Samples 5792] time/batch: 0.258s training loss: 0.4789, training accuracy: 0.7712\n",
      "[Epoch 0][Batch 181][Samples 5824] time/batch: 0.254s training loss: 0.4772, training accuracy: 0.7721\n",
      "[Epoch 0][Batch 182][Samples 5856] time/batch: 0.255s training loss: 0.4781, training accuracy: 0.7717\n",
      "[Epoch 0][Batch 183][Samples 5888] time/batch: 0.257s training loss: 0.4767, training accuracy: 0.7724\n",
      "[Epoch 0][Batch 184][Samples 5920] time/batch: 0.260s training loss: 0.4768, training accuracy: 0.7721\n",
      "[Epoch 0][Batch 185][Samples 5952] time/batch: 0.257s training loss: 0.4761, training accuracy: 0.7732\n",
      "[Epoch 0][Batch 186][Samples 5984] time/batch: 0.262s training loss: 0.4757, training accuracy: 0.7734\n",
      "[Epoch 0][Batch 187][Samples 6016] time/batch: 0.254s training loss: 0.4753, training accuracy: 0.7736\n",
      "[Epoch 0][Batch 188][Samples 6048] time/batch: 0.271s training loss: 0.4746, training accuracy: 0.7740\n",
      "[Epoch 0][Batch 189][Samples 6080] time/batch: 0.257s training loss: 0.4745, training accuracy: 0.7742\n",
      "[Epoch 0][Batch 190][Samples 6112] time/batch: 0.258s training loss: 0.4742, training accuracy: 0.7744\n",
      "[Epoch 0][Batch 191][Samples 6144] time/batch: 0.257s training loss: 0.4738, training accuracy: 0.7744\n",
      "[Epoch 0][Batch 192][Samples 6176] time/batch: 0.254s training loss: 0.4732, training accuracy: 0.7749\n",
      "[Epoch 0][Batch 193][Samples 6208] time/batch: 0.260s training loss: 0.4720, training accuracy: 0.7755\n",
      "[Epoch 0][Batch 194][Samples 6240] time/batch: 0.253s training loss: 0.4724, training accuracy: 0.7752\n",
      "[Epoch 0][Batch 195][Samples 6272] time/batch: 0.256s training loss: 0.4713, training accuracy: 0.7755\n",
      "[Epoch 0][Batch 196][Samples 6304] time/batch: 0.255s training loss: 0.4717, training accuracy: 0.7751\n",
      "[Epoch 0][Batch 197][Samples 6336] time/batch: 0.262s training loss: 0.4710, training accuracy: 0.7753\n",
      "[Epoch 0][Batch 198][Samples 6368] time/batch: 0.258s training loss: 0.4700, training accuracy: 0.7758\n",
      "[Epoch 0][Batch 199][Samples 6400] time/batch: 0.255s training loss: 0.4705, training accuracy: 0.7756\n",
      "[Epoch 0][Batch 200][Samples 6432] time/batch: 0.262s training loss: 0.4703, training accuracy: 0.7757\n",
      "[Epoch 0][Batch 201][Samples 6464] time/batch: 0.262s training loss: 0.4702, training accuracy: 0.7758\n",
      "[Epoch 0][Batch 202][Samples 6496] time/batch: 0.255s training loss: 0.4693, training accuracy: 0.7762\n",
      "[Epoch 0][Batch 203][Samples 6528] time/batch: 0.257s training loss: 0.4693, training accuracy: 0.7760\n",
      "[Epoch 0][Batch 204][Samples 6560] time/batch: 0.253s training loss: 0.4698, training accuracy: 0.7758\n",
      "[Epoch 0][Batch 205][Samples 6592] time/batch: 0.260s training loss: 0.4694, training accuracy: 0.7759\n",
      "[Epoch 0][Batch 206][Samples 6624] time/batch: 0.259s training loss: 0.4689, training accuracy: 0.7763\n",
      "[Epoch 0][Batch 207][Samples 6656] time/batch: 0.260s training loss: 0.4684, training accuracy: 0.7764\n",
      "[Epoch 0][Batch 208][Samples 6688] time/batch: 0.257s training loss: 0.4680, training accuracy: 0.7768\n",
      "[Epoch 0][Batch 209][Samples 6720] time/batch: 0.264s training loss: 0.4674, training accuracy: 0.7768\n",
      "[Epoch 0][Batch 210][Samples 6752] time/batch: 0.257s training loss: 0.4672, training accuracy: 0.7767\n",
      "[Epoch 0][Batch 211][Samples 6784] time/batch: 0.258s training loss: 0.4673, training accuracy: 0.7770\n",
      "[Epoch 0][Batch 212][Samples 6816] time/batch: 0.256s training loss: 0.4663, training accuracy: 0.7776\n",
      "[Epoch 0][Batch 213][Samples 6848] time/batch: 0.257s training loss: 0.4663, training accuracy: 0.7777\n",
      "[Epoch 0][Batch 214][Samples 6880] time/batch: 0.258s training loss: 0.4674, training accuracy: 0.7776\n",
      "[Epoch 0][Batch 215][Samples 6912] time/batch: 0.260s training loss: 0.4673, training accuracy: 0.7775\n",
      "[Epoch 0][Batch 216][Samples 6944] time/batch: 0.263s training loss: 0.4669, training accuracy: 0.7779\n",
      "[Epoch 0][Batch 217][Samples 6976] time/batch: 0.259s training loss: 0.4666, training accuracy: 0.7780\n",
      "[Epoch 0][Batch 218][Samples 7008] time/batch: 0.256s training loss: 0.4665, training accuracy: 0.7781\n",
      "[Epoch 0][Batch 219][Samples 7040] time/batch: 0.260s training loss: 0.4664, training accuracy: 0.7777\n",
      "[Epoch 0][Batch 220][Samples 7072] time/batch: 0.258s training loss: 0.4656, training accuracy: 0.7780\n",
      "[Epoch 0][Batch 221][Samples 7104] time/batch: 0.262s training loss: 0.4653, training accuracy: 0.7784\n",
      "[Epoch 0][Batch 222][Samples 7136] time/batch: 0.258s training loss: 0.4649, training accuracy: 0.7784\n",
      "[Epoch 0][Batch 223][Samples 7168] time/batch: 0.258s training loss: 0.4639, training accuracy: 0.7792\n",
      "[Epoch 0][Batch 224][Samples 7200] time/batch: 0.256s training loss: 0.4636, training accuracy: 0.7789\n",
      "[Epoch 0][Batch 225][Samples 7232] time/batch: 0.258s training loss: 0.4626, training accuracy: 0.7795\n",
      "[Epoch 0][Batch 226][Samples 7264] time/batch: 0.255s training loss: 0.4615, training accuracy: 0.7800\n",
      "[Epoch 0][Batch 227][Samples 7296] time/batch: 0.262s training loss: 0.4602, training accuracy: 0.7808\n",
      "[Epoch 0][Batch 228][Samples 7328] time/batch: 0.262s training loss: 0.4599, training accuracy: 0.7808\n",
      "[Epoch 0][Batch 229][Samples 7360] time/batch: 0.259s training loss: 0.4594, training accuracy: 0.7812\n",
      "[Epoch 0][Batch 230][Samples 7392] time/batch: 0.258s training loss: 0.4596, training accuracy: 0.7812\n",
      "[Epoch 0][Batch 231][Samples 7424] time/batch: 0.270s training loss: 0.4589, training accuracy: 0.7817\n",
      "[Epoch 0][Batch 232][Samples 7456] time/batch: 0.265s training loss: 0.4587, training accuracy: 0.7817\n",
      "[Epoch 0][Batch 233][Samples 7488] time/batch: 0.257s training loss: 0.4584, training accuracy: 0.7819\n",
      "[Epoch 0][Batch 234][Samples 7520] time/batch: 0.254s training loss: 0.4580, training accuracy: 0.7824\n",
      "[Epoch 0][Batch 235][Samples 7552] time/batch: 0.268s training loss: 0.4570, training accuracy: 0.7830\n",
      "[Epoch 0][Batch 236][Samples 7584] time/batch: 0.264s training loss: 0.4566, training accuracy: 0.7834\n",
      "[Epoch 0][Batch 237][Samples 7616] time/batch: 0.266s training loss: 0.4563, training accuracy: 0.7835\n",
      "[Epoch 0][Batch 238][Samples 7648] time/batch: 0.254s training loss: 0.4564, training accuracy: 0.7836\n",
      "[Epoch 0][Batch 239][Samples 7680] time/batch: 0.262s training loss: 0.4562, training accuracy: 0.7835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 240][Samples 7712] time/batch: 0.257s training loss: 0.4553, training accuracy: 0.7841\n",
      "[Epoch 0][Batch 241][Samples 7744] time/batch: 0.262s training loss: 0.4551, training accuracy: 0.7842\n",
      "[Epoch 0][Batch 242][Samples 7776] time/batch: 0.254s training loss: 0.4549, training accuracy: 0.7847\n",
      "[Epoch 0][Batch 243][Samples 7808] time/batch: 0.267s training loss: 0.4546, training accuracy: 0.7850\n",
      "[Epoch 0][Batch 244][Samples 7840] time/batch: 0.266s training loss: 0.4550, training accuracy: 0.7846\n",
      "[Epoch 0][Batch 245][Samples 7872] time/batch: 0.269s training loss: 0.4547, training accuracy: 0.7849\n",
      "[Epoch 0][Batch 246][Samples 7904] time/batch: 0.266s training loss: 0.4542, training accuracy: 0.7852\n",
      "[Epoch 0][Batch 247][Samples 7936] time/batch: 0.260s training loss: 0.4536, training accuracy: 0.7857\n",
      "[Epoch 0][Batch 248][Samples 7968] time/batch: 0.270s training loss: 0.4531, training accuracy: 0.7860\n",
      "[Epoch 0][Batch 249][Samples 8000] time/batch: 0.260s training loss: 0.4519, training accuracy: 0.7866\n",
      "[Epoch 0][Batch 250][Samples 8032] time/batch: 0.264s training loss: 0.4519, training accuracy: 0.7867\n",
      "[Epoch 0][Batch 251][Samples 8064] time/batch: 0.257s training loss: 0.4509, training accuracy: 0.7871\n",
      "[Epoch 0][Batch 252][Samples 8096] time/batch: 0.257s training loss: 0.4500, training accuracy: 0.7875\n",
      "[Epoch 0][Batch 253][Samples 8128] time/batch: 0.260s training loss: 0.4499, training accuracy: 0.7874\n",
      "[Epoch 0][Batch 254][Samples 8160] time/batch: 0.266s training loss: 0.4502, training accuracy: 0.7873\n",
      "[Epoch 0][Batch 255][Samples 8192] time/batch: 0.260s training loss: 0.4501, training accuracy: 0.7877\n",
      "[Epoch 0][Batch 256][Samples 8224] time/batch: 0.257s training loss: 0.4505, training accuracy: 0.7877\n",
      "[Epoch 0][Batch 257][Samples 8256] time/batch: 0.256s training loss: 0.4499, training accuracy: 0.7879\n",
      "[Epoch 0][Batch 258][Samples 8288] time/batch: 0.259s training loss: 0.4494, training accuracy: 0.7882\n",
      "[Epoch 0][Batch 259][Samples 8320] time/batch: 0.256s training loss: 0.4485, training accuracy: 0.7888\n",
      "[Epoch 0][Batch 260][Samples 8352] time/batch: 0.260s training loss: 0.4478, training accuracy: 0.7892\n",
      "[Epoch 0][Batch 261][Samples 8384] time/batch: 0.255s training loss: 0.4478, training accuracy: 0.7892\n",
      "[Epoch 0][Batch 262][Samples 8416] time/batch: 0.255s training loss: 0.4471, training accuracy: 0.7896\n",
      "[Epoch 0][Batch 263][Samples 8448] time/batch: 0.260s training loss: 0.4466, training accuracy: 0.7897\n",
      "[Epoch 0][Batch 264][Samples 8480] time/batch: 0.258s training loss: 0.4466, training accuracy: 0.7896\n",
      "[Epoch 0][Batch 265][Samples 8512] time/batch: 0.256s training loss: 0.4456, training accuracy: 0.7902\n",
      "[Epoch 0][Batch 266][Samples 8544] time/batch: 0.260s training loss: 0.4450, training accuracy: 0.7905\n",
      "[Epoch 0][Batch 267][Samples 8576] time/batch: 0.268s training loss: 0.4443, training accuracy: 0.7908\n",
      "[Epoch 0][Batch 268][Samples 8608] time/batch: 0.266s training loss: 0.4433, training accuracy: 0.7915\n",
      "[Epoch 0][Batch 269][Samples 8640] time/batch: 0.257s training loss: 0.4430, training accuracy: 0.7913\n",
      "[Epoch 0][Batch 270][Samples 8672] time/batch: 0.269s training loss: 0.4432, training accuracy: 0.7914\n",
      "[Epoch 0][Batch 271][Samples 8704] time/batch: 0.256s training loss: 0.4428, training accuracy: 0.7915\n",
      "[Epoch 0][Batch 272][Samples 8736] time/batch: 0.261s training loss: 0.4429, training accuracy: 0.7914\n",
      "[Epoch 0][Batch 273][Samples 8768] time/batch: 0.255s training loss: 0.4428, training accuracy: 0.7915\n",
      "[Epoch 0][Batch 274][Samples 8800] time/batch: 0.258s training loss: 0.4424, training accuracy: 0.7917\n",
      "[Epoch 0][Batch 275][Samples 8832] time/batch: 0.258s training loss: 0.4414, training accuracy: 0.7921\n",
      "[Epoch 0][Batch 276][Samples 8864] time/batch: 0.271s training loss: 0.4410, training accuracy: 0.7926\n",
      "[Epoch 0][Batch 277][Samples 8896] time/batch: 0.263s training loss: 0.4408, training accuracy: 0.7927\n",
      "[Epoch 0][Batch 278][Samples 8928] time/batch: 0.270s training loss: 0.4405, training accuracy: 0.7928\n",
      "[Epoch 0][Batch 279][Samples 8960] time/batch: 0.259s training loss: 0.4401, training accuracy: 0.7929\n",
      "[Epoch 0][Batch 280][Samples 8992] time/batch: 0.259s training loss: 0.4395, training accuracy: 0.7933\n",
      "[Epoch 0][Batch 281][Samples 9024] time/batch: 0.260s training loss: 0.4388, training accuracy: 0.7934\n",
      "[Epoch 0][Batch 282][Samples 9056] time/batch: 0.269s training loss: 0.4384, training accuracy: 0.7937\n",
      "[Epoch 0][Batch 283][Samples 9088] time/batch: 0.264s training loss: 0.4378, training accuracy: 0.7940\n",
      "[Epoch 0][Batch 284][Samples 9120] time/batch: 0.260s training loss: 0.4374, training accuracy: 0.7942\n",
      "[Epoch 0][Batch 285][Samples 9152] time/batch: 0.262s training loss: 0.4382, training accuracy: 0.7936\n",
      "[Epoch 0][Batch 286][Samples 9184] time/batch: 0.260s training loss: 0.4382, training accuracy: 0.7934\n",
      "[Epoch 0][Batch 287][Samples 9216] time/batch: 0.255s training loss: 0.4381, training accuracy: 0.7936\n",
      "[Epoch 0][Batch 288][Samples 9248] time/batch: 0.270s training loss: 0.4381, training accuracy: 0.7939\n",
      "[Epoch 0][Batch 289][Samples 9280] time/batch: 0.255s training loss: 0.4377, training accuracy: 0.7942\n",
      "[Epoch 0][Batch 290][Samples 9312] time/batch: 0.260s training loss: 0.4378, training accuracy: 0.7939\n",
      "[Epoch 0][Batch 291][Samples 9344] time/batch: 0.258s training loss: 0.4371, training accuracy: 0.7944\n",
      "[Epoch 0][Batch 292][Samples 9376] time/batch: 0.259s training loss: 0.4365, training accuracy: 0.7946\n",
      "[Epoch 0][Batch 293][Samples 9408] time/batch: 0.261s training loss: 0.4361, training accuracy: 0.7949\n",
      "[Epoch 0][Batch 294][Samples 9440] time/batch: 0.267s training loss: 0.4357, training accuracy: 0.7952\n",
      "[Epoch 0][Batch 295][Samples 9472] time/batch: 0.269s training loss: 0.4354, training accuracy: 0.7954\n",
      "[Epoch 0][Batch 296][Samples 9504] time/batch: 0.272s training loss: 0.4358, training accuracy: 0.7952\n",
      "[Epoch 0][Batch 297][Samples 9536] time/batch: 0.258s training loss: 0.4348, training accuracy: 0.7957\n",
      "[Epoch 0][Batch 298][Samples 9568] time/batch: 0.262s training loss: 0.4342, training accuracy: 0.7961\n",
      "[Epoch 0][Batch 299][Samples 9600] time/batch: 0.259s training loss: 0.4334, training accuracy: 0.7965\n",
      "[Epoch 0][Batch 300][Samples 9632] time/batch: 0.259s training loss: 0.4333, training accuracy: 0.7965\n",
      "[Epoch 0][Batch 301][Samples 9664] time/batch: 0.259s training loss: 0.4332, training accuracy: 0.7964\n",
      "[Epoch 0][Batch 302][Samples 9696] time/batch: 0.257s training loss: 0.4330, training accuracy: 0.7966\n",
      "[Epoch 0][Batch 303][Samples 9728] time/batch: 0.262s training loss: 0.4325, training accuracy: 0.7970\n",
      "[Epoch 0][Batch 304][Samples 9760] time/batch: 0.254s training loss: 0.4322, training accuracy: 0.7972\n",
      "[Epoch 0][Batch 305][Samples 9792] time/batch: 0.261s training loss: 0.4318, training accuracy: 0.7975\n",
      "[Epoch 0][Batch 306][Samples 9824] time/batch: 0.257s training loss: 0.4322, training accuracy: 0.7976\n",
      "[Epoch 0][Batch 307][Samples 9856] time/batch: 0.273s training loss: 0.4318, training accuracy: 0.7980\n",
      "[Epoch 0][Batch 308][Samples 9888] time/batch: 0.257s training loss: 0.4314, training accuracy: 0.7982\n",
      "[Epoch 0][Batch 309][Samples 9920] time/batch: 0.273s training loss: 0.4314, training accuracy: 0.7983\n",
      "[Epoch 0][Batch 310][Samples 9952] time/batch: 0.270s training loss: 0.4311, training accuracy: 0.7984\n",
      "[Epoch 0][Batch 311][Samples 9984] time/batch: 0.260s training loss: 0.4304, training accuracy: 0.7988\n",
      "[Epoch 0][Batch 312][Samples 10016] time/batch: 0.256s training loss: 0.4300, training accuracy: 0.7991\n",
      "[Epoch 0][Batch 313][Samples 10048] time/batch: 0.261s training loss: 0.4304, training accuracy: 0.7993\n",
      "[Epoch 0][Batch 314][Samples 10080] time/batch: 0.255s training loss: 0.4306, training accuracy: 0.7993\n",
      "[Epoch 0][Batch 315][Samples 10112] time/batch: 0.277s training loss: 0.4302, training accuracy: 0.7996\n",
      "[Epoch 0][Batch 316][Samples 10144] time/batch: 0.260s training loss: 0.4300, training accuracy: 0.7997\n",
      "[Epoch 0][Batch 317][Samples 10176] time/batch: 0.262s training loss: 0.4293, training accuracy: 0.8001\n",
      "[Epoch 0][Batch 318][Samples 10208] time/batch: 0.256s training loss: 0.4294, training accuracy: 0.7999\n",
      "[Epoch 0][Batch 319][Samples 10240] time/batch: 0.264s training loss: 0.4290, training accuracy: 0.8001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 320][Samples 10272] time/batch: 0.259s training loss: 0.4295, training accuracy: 0.7996\n",
      "[Epoch 0][Batch 321][Samples 10304] time/batch: 0.265s training loss: 0.4292, training accuracy: 0.7997\n",
      "[Epoch 0][Batch 322][Samples 10336] time/batch: 0.264s training loss: 0.4293, training accuracy: 0.7995\n",
      "[Epoch 0][Batch 323][Samples 10368] time/batch: 0.259s training loss: 0.4288, training accuracy: 0.7999\n",
      "[Epoch 0][Batch 324][Samples 10400] time/batch: 0.255s training loss: 0.4282, training accuracy: 0.8003\n",
      "[Epoch 0][Batch 325][Samples 10432] time/batch: 0.257s training loss: 0.4279, training accuracy: 0.8006\n",
      "[Epoch 0][Batch 326][Samples 10464] time/batch: 0.259s training loss: 0.4275, training accuracy: 0.8007\n",
      "[Epoch 0][Batch 327][Samples 10496] time/batch: 0.267s training loss: 0.4277, training accuracy: 0.8009\n",
      "[Epoch 0][Batch 328][Samples 10528] time/batch: 0.261s training loss: 0.4274, training accuracy: 0.8011\n",
      "[Epoch 0][Batch 329][Samples 10560] time/batch: 0.261s training loss: 0.4269, training accuracy: 0.8015\n",
      "[Epoch 0][Batch 330][Samples 10592] time/batch: 0.255s training loss: 0.4264, training accuracy: 0.8017\n",
      "[Epoch 0][Batch 331][Samples 10624] time/batch: 0.261s training loss: 0.4266, training accuracy: 0.8017\n",
      "[Epoch 0][Batch 332][Samples 10656] time/batch: 0.261s training loss: 0.4271, training accuracy: 0.8016\n",
      "[Epoch 0][Batch 333][Samples 10688] time/batch: 0.260s training loss: 0.4266, training accuracy: 0.8017\n",
      "[Epoch 0][Batch 334][Samples 10720] time/batch: 0.266s training loss: 0.4264, training accuracy: 0.8018\n",
      "[Epoch 0][Batch 335][Samples 10752] time/batch: 0.256s training loss: 0.4258, training accuracy: 0.8022\n",
      "[Epoch 0][Batch 336][Samples 10784] time/batch: 0.266s training loss: 0.4250, training accuracy: 0.8026\n",
      "[Epoch 0][Batch 337][Samples 10816] time/batch: 0.261s training loss: 0.4246, training accuracy: 0.8029\n",
      "[Epoch 0][Batch 338][Samples 10848] time/batch: 0.263s training loss: 0.4239, training accuracy: 0.8033\n",
      "[Epoch 0][Batch 339][Samples 10880] time/batch: 0.256s training loss: 0.4242, training accuracy: 0.8030\n",
      "[Epoch 0][Batch 340][Samples 10912] time/batch: 0.263s training loss: 0.4235, training accuracy: 0.8035\n",
      "[Epoch 0][Batch 341][Samples 10944] time/batch: 0.263s training loss: 0.4229, training accuracy: 0.8037\n",
      "[Epoch 0][Batch 342][Samples 10976] time/batch: 0.261s training loss: 0.4227, training accuracy: 0.8037\n",
      "[Epoch 0][Batch 343][Samples 11008] time/batch: 0.255s training loss: 0.4225, training accuracy: 0.8038\n",
      "[Epoch 0][Batch 344][Samples 11040] time/batch: 0.260s training loss: 0.4219, training accuracy: 0.8041\n",
      "[Epoch 0][Batch 345][Samples 11072] time/batch: 0.270s training loss: 0.4221, training accuracy: 0.8041\n",
      "[Epoch 0][Batch 346][Samples 11104] time/batch: 0.270s training loss: 0.4223, training accuracy: 0.8042\n",
      "[Epoch 0][Batch 347][Samples 11136] time/batch: 0.263s training loss: 0.4218, training accuracy: 0.8046\n",
      "[Epoch 0][Batch 348][Samples 11168] time/batch: 0.259s training loss: 0.4212, training accuracy: 0.8049\n",
      "[Epoch 0][Batch 349][Samples 11200] time/batch: 0.260s training loss: 0.4210, training accuracy: 0.8050\n",
      "[Epoch 0][Batch 350][Samples 11232] time/batch: 0.258s training loss: 0.4207, training accuracy: 0.8051\n",
      "[Epoch 0][Batch 351][Samples 11264] time/batch: 0.261s training loss: 0.4207, training accuracy: 0.8051\n",
      "[Epoch 0][Batch 352][Samples 11296] time/batch: 0.255s training loss: 0.4208, training accuracy: 0.8049\n",
      "[Epoch 0][Batch 353][Samples 11328] time/batch: 0.256s training loss: 0.4205, training accuracy: 0.8052\n",
      "[Epoch 0][Batch 354][Samples 11360] time/batch: 0.254s training loss: 0.4198, training accuracy: 0.8056\n",
      "[Epoch 0][Batch 355][Samples 11392] time/batch: 0.261s training loss: 0.4201, training accuracy: 0.8056\n",
      "[Epoch 0][Batch 356][Samples 11424] time/batch: 0.268s training loss: 0.4198, training accuracy: 0.8057\n",
      "[Epoch 0][Batch 357][Samples 11456] time/batch: 0.271s training loss: 0.4192, training accuracy: 0.8059\n",
      "[Epoch 0][Batch 358][Samples 11488] time/batch: 0.256s training loss: 0.4186, training accuracy: 0.8062\n",
      "[Epoch 0][Batch 359][Samples 11520] time/batch: 0.257s training loss: 0.4184, training accuracy: 0.8063\n",
      "[Epoch 0][Batch 360][Samples 11552] time/batch: 0.256s training loss: 0.4181, training accuracy: 0.8066\n",
      "[Epoch 0][Batch 361][Samples 11584] time/batch: 0.270s training loss: 0.4184, training accuracy: 0.8064\n",
      "[Epoch 0][Batch 362][Samples 11616] time/batch: 0.263s training loss: 0.4181, training accuracy: 0.8065\n",
      "[Epoch 0][Batch 363][Samples 11648] time/batch: 0.264s training loss: 0.4182, training accuracy: 0.8064\n",
      "[Epoch 0][Batch 364][Samples 11680] time/batch: 0.263s training loss: 0.4182, training accuracy: 0.8063\n",
      "[Epoch 0][Batch 365][Samples 11712] time/batch: 0.262s training loss: 0.4177, training accuracy: 0.8066\n",
      "[Epoch 0][Batch 366][Samples 11744] time/batch: 0.260s training loss: 0.4176, training accuracy: 0.8067\n",
      "[Epoch 0][Batch 367][Samples 11776] time/batch: 0.262s training loss: 0.4176, training accuracy: 0.8066\n",
      "[Epoch 0][Batch 368][Samples 11808] time/batch: 0.271s training loss: 0.4173, training accuracy: 0.8067\n",
      "[Epoch 0][Batch 369][Samples 11840] time/batch: 0.262s training loss: 0.4168, training accuracy: 0.8070\n",
      "[Epoch 0][Batch 370][Samples 11872] time/batch: 0.268s training loss: 0.4164, training accuracy: 0.8072\n",
      "[Epoch 0][Batch 371][Samples 11904] time/batch: 0.270s training loss: 0.4160, training accuracy: 0.8074\n",
      "[Epoch 0][Batch 372][Samples 11936] time/batch: 0.259s training loss: 0.4158, training accuracy: 0.8076\n",
      "[Epoch 0][Batch 373][Samples 11968] time/batch: 0.255s training loss: 0.4159, training accuracy: 0.8075\n",
      "[Epoch 0][Batch 374][Samples 12000] time/batch: 0.261s training loss: 0.4155, training accuracy: 0.8077\n",
      "[Epoch 0][Batch 375][Samples 12032] time/batch: 0.258s training loss: 0.4151, training accuracy: 0.8079\n",
      "[Epoch 0][Batch 376][Samples 12064] time/batch: 0.265s training loss: 0.4148, training accuracy: 0.8081\n",
      "[Epoch 0][Batch 377][Samples 12096] time/batch: 0.258s training loss: 0.4140, training accuracy: 0.8086\n",
      "[Epoch 0][Batch 378][Samples 12128] time/batch: 0.260s training loss: 0.4136, training accuracy: 0.8088\n",
      "[Epoch 0][Batch 379][Samples 12160] time/batch: 0.255s training loss: 0.4136, training accuracy: 0.8088\n",
      "[Epoch 0][Batch 380][Samples 12192] time/batch: 0.258s training loss: 0.4134, training accuracy: 0.8091\n",
      "[Epoch 0][Batch 381][Samples 12224] time/batch: 0.255s training loss: 0.4131, training accuracy: 0.8093\n",
      "[Epoch 0][Batch 382][Samples 12256] time/batch: 0.260s training loss: 0.4124, training accuracy: 0.8097\n",
      "[Epoch 0][Batch 383][Samples 12288] time/batch: 0.255s training loss: 0.4125, training accuracy: 0.8097\n",
      "[Epoch 0][Batch 384][Samples 12320] time/batch: 0.271s training loss: 0.4122, training accuracy: 0.8098\n",
      "[Epoch 0][Batch 385][Samples 12352] time/batch: 0.257s training loss: 0.4120, training accuracy: 0.8099\n",
      "[Epoch 0][Batch 386][Samples 12384] time/batch: 0.260s training loss: 0.4121, training accuracy: 0.8098\n",
      "[Epoch 0][Batch 387][Samples 12416] time/batch: 0.260s training loss: 0.4124, training accuracy: 0.8098\n",
      "[Epoch 0][Batch 388][Samples 12448] time/batch: 0.258s training loss: 0.4123, training accuracy: 0.8096\n",
      "[Epoch 0][Batch 389][Samples 12480] time/batch: 0.261s training loss: 0.4123, training accuracy: 0.8096\n",
      "[Epoch 0][Batch 390][Samples 12512] time/batch: 0.262s training loss: 0.4125, training accuracy: 0.8096\n",
      "[Epoch 0][Batch 391][Samples 12544] time/batch: 0.260s training loss: 0.4123, training accuracy: 0.8098\n",
      "[Epoch 0][Batch 392][Samples 12576] time/batch: 0.258s training loss: 0.4118, training accuracy: 0.8102\n",
      "[Epoch 0][Batch 393][Samples 12608] time/batch: 0.256s training loss: 0.4118, training accuracy: 0.8103\n",
      "[Epoch 0][Batch 394][Samples 12640] time/batch: 0.262s training loss: 0.4119, training accuracy: 0.8103\n",
      "[Epoch 0][Batch 395][Samples 12672] time/batch: 0.257s training loss: 0.4119, training accuracy: 0.8102\n",
      "[Epoch 0][Batch 396][Samples 12704] time/batch: 0.260s training loss: 0.4116, training accuracy: 0.8105\n",
      "[Epoch 0][Batch 397][Samples 12736] time/batch: 0.259s training loss: 0.4121, training accuracy: 0.8105\n",
      "[Epoch 0][Batch 398][Samples 12768] time/batch: 0.256s training loss: 0.4117, training accuracy: 0.8108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 399][Samples 12800] time/batch: 0.263s training loss: 0.4121, training accuracy: 0.8107\n",
      "[Epoch 0][Batch 400][Samples 12832] time/batch: 0.259s training loss: 0.4118, training accuracy: 0.8108\n",
      "[Epoch 0][Batch 401][Samples 12864] time/batch: 0.262s training loss: 0.4113, training accuracy: 0.8111\n",
      "[Epoch 0][Batch 402][Samples 12896] time/batch: 0.259s training loss: 0.4111, training accuracy: 0.8112\n",
      "[Epoch 0][Batch 403][Samples 12928] time/batch: 0.266s training loss: 0.4107, training accuracy: 0.8113\n",
      "[Epoch 0][Batch 404][Samples 12960] time/batch: 0.259s training loss: 0.4104, training accuracy: 0.8114\n",
      "[Epoch 0][Batch 405][Samples 12992] time/batch: 0.261s training loss: 0.4102, training accuracy: 0.8114\n",
      "[Epoch 0][Batch 406][Samples 13024] time/batch: 0.256s training loss: 0.4100, training accuracy: 0.8115\n",
      "[Epoch 0][Batch 407][Samples 13056] time/batch: 0.262s training loss: 0.4096, training accuracy: 0.8117\n",
      "[Epoch 0][Batch 408][Samples 13088] time/batch: 0.258s training loss: 0.4095, training accuracy: 0.8116\n",
      "[Epoch 0][Batch 409][Samples 13120] time/batch: 0.265s training loss: 0.4093, training accuracy: 0.8115\n",
      "[Epoch 0][Batch 410][Samples 13152] time/batch: 0.258s training loss: 0.4093, training accuracy: 0.8114\n",
      "[Epoch 0][Batch 411][Samples 13184] time/batch: 0.265s training loss: 0.4093, training accuracy: 0.8114\n",
      "[Epoch 0][Batch 412][Samples 13216] time/batch: 0.263s training loss: 0.4096, training accuracy: 0.8112\n",
      "[Epoch 0][Batch 413][Samples 13248] time/batch: 0.258s training loss: 0.4093, training accuracy: 0.8114\n",
      "[Epoch 0][Batch 414][Samples 13280] time/batch: 0.269s training loss: 0.4088, training accuracy: 0.8115\n",
      "[Epoch 0][Batch 415][Samples 13312] time/batch: 0.258s training loss: 0.4090, training accuracy: 0.8115\n",
      "[Epoch 0][Batch 416][Samples 13344] time/batch: 0.256s training loss: 0.4088, training accuracy: 0.8116\n",
      "[Epoch 0][Batch 417][Samples 13376] time/batch: 0.263s training loss: 0.4083, training accuracy: 0.8118\n",
      "[Epoch 0][Batch 418][Samples 13408] time/batch: 0.259s training loss: 0.4080, training accuracy: 0.8119\n",
      "[Epoch 0][Batch 419][Samples 13440] time/batch: 0.258s training loss: 0.4078, training accuracy: 0.8121\n",
      "[Epoch 0][Batch 420][Samples 13472] time/batch: 0.264s training loss: 0.4073, training accuracy: 0.8124\n",
      "[Epoch 0][Batch 421][Samples 13504] time/batch: 0.259s training loss: 0.4069, training accuracy: 0.8126\n",
      "[Epoch 0][Batch 422][Samples 13536] time/batch: 0.267s training loss: 0.4066, training accuracy: 0.8128\n",
      "[Epoch 0][Batch 423][Samples 13568] time/batch: 0.261s training loss: 0.4061, training accuracy: 0.8130\n",
      "[Epoch 0][Batch 424][Samples 13600] time/batch: 0.255s training loss: 0.4057, training accuracy: 0.8133\n",
      "[Epoch 0][Batch 425][Samples 13632] time/batch: 0.260s training loss: 0.4056, training accuracy: 0.8134\n",
      "[Epoch 0][Batch 426][Samples 13664] time/batch: 0.257s training loss: 0.4057, training accuracy: 0.8134\n",
      "[Epoch 0][Batch 427][Samples 13696] time/batch: 0.262s training loss: 0.4054, training accuracy: 0.8135\n",
      "[Epoch 0][Batch 428][Samples 13728] time/batch: 0.255s training loss: 0.4052, training accuracy: 0.8137\n",
      "[Epoch 0][Batch 429][Samples 13760] time/batch: 0.262s training loss: 0.4052, training accuracy: 0.8137\n",
      "[Epoch 0][Batch 430][Samples 13792] time/batch: 0.258s training loss: 0.4050, training accuracy: 0.8139\n",
      "[Epoch 0][Batch 431][Samples 13824] time/batch: 0.263s training loss: 0.4055, training accuracy: 0.8138\n",
      "[Epoch 0][Batch 432][Samples 13856] time/batch: 0.258s training loss: 0.4054, training accuracy: 0.8140\n",
      "[Epoch 0][Batch 433][Samples 13888] time/batch: 0.267s training loss: 0.4052, training accuracy: 0.8142\n",
      "[Epoch 0][Batch 434][Samples 13920] time/batch: 0.256s training loss: 0.4051, training accuracy: 0.8142\n",
      "[Epoch 0][Batch 435][Samples 13952] time/batch: 0.261s training loss: 0.4047, training accuracy: 0.8145\n",
      "[Epoch 0][Batch 436][Samples 13984] time/batch: 0.258s training loss: 0.4043, training accuracy: 0.8146\n",
      "[Epoch 0][Batch 437][Samples 14016] time/batch: 0.258s training loss: 0.4037, training accuracy: 0.8149\n",
      "[Epoch 0][Batch 438][Samples 14048] time/batch: 0.255s training loss: 0.4033, training accuracy: 0.8152\n",
      "[Epoch 0][Batch 439][Samples 14080] time/batch: 0.257s training loss: 0.4027, training accuracy: 0.8155\n",
      "[Epoch 0][Batch 440][Samples 14112] time/batch: 0.271s training loss: 0.4027, training accuracy: 0.8155\n",
      "[Epoch 0][Batch 441][Samples 14144] time/batch: 0.266s training loss: 0.4025, training accuracy: 0.8157\n",
      "[Epoch 0][Batch 442][Samples 14176] time/batch: 0.266s training loss: 0.4024, training accuracy: 0.8155\n",
      "[Epoch 0][Batch 443][Samples 14208] time/batch: 0.262s training loss: 0.4020, training accuracy: 0.8159\n",
      "[Epoch 0][Batch 444][Samples 14240] time/batch: 0.262s training loss: 0.4013, training accuracy: 0.8162\n",
      "[Epoch 0][Batch 445][Samples 14272] time/batch: 0.264s training loss: 0.4010, training accuracy: 0.8163\n",
      "[Epoch 0][Batch 446][Samples 14304] time/batch: 0.256s training loss: 0.4010, training accuracy: 0.8163\n",
      "[Epoch 0][Batch 447][Samples 14336] time/batch: 0.260s training loss: 0.4012, training accuracy: 0.8163\n",
      "[Epoch 0][Batch 448][Samples 14368] time/batch: 0.255s training loss: 0.4012, training accuracy: 0.8163\n",
      "[Epoch 0][Batch 449][Samples 14400] time/batch: 0.258s training loss: 0.4015, training accuracy: 0.8162\n",
      "[Epoch 0][Batch 450][Samples 14432] time/batch: 0.256s training loss: 0.4016, training accuracy: 0.8162\n",
      "[Epoch 0][Batch 451][Samples 14464] time/batch: 0.261s training loss: 0.4023, training accuracy: 0.8162\n",
      "[Epoch 0][Batch 452][Samples 14496] time/batch: 0.254s training loss: 0.4021, training accuracy: 0.8163\n",
      "[Epoch 0][Batch 453][Samples 14528] time/batch: 0.260s training loss: 0.4020, training accuracy: 0.8164\n",
      "[Epoch 0][Batch 454][Samples 14560] time/batch: 0.257s training loss: 0.4020, training accuracy: 0.8163\n",
      "[Epoch 0][Batch 455][Samples 14592] time/batch: 0.264s training loss: 0.4019, training accuracy: 0.8164\n",
      "[Epoch 0][Batch 456][Samples 14624] time/batch: 0.265s training loss: 0.4013, training accuracy: 0.8167\n",
      "[Epoch 0][Batch 457][Samples 14656] time/batch: 0.258s training loss: 0.4011, training accuracy: 0.8167\n",
      "[Epoch 0][Batch 458][Samples 14688] time/batch: 0.260s training loss: 0.4010, training accuracy: 0.8167\n",
      "[Epoch 0][Batch 459][Samples 14720] time/batch: 0.259s training loss: 0.4007, training accuracy: 0.8168\n",
      "[Epoch 0][Batch 460][Samples 14752] time/batch: 0.265s training loss: 0.4005, training accuracy: 0.8170\n",
      "[Epoch 0][Batch 461][Samples 14784] time/batch: 0.269s training loss: 0.4002, training accuracy: 0.8173\n",
      "[Epoch 0][Batch 462][Samples 14816] time/batch: 0.260s training loss: 0.4000, training accuracy: 0.8175\n",
      "[Epoch 0][Batch 463][Samples 14848] time/batch: 0.260s training loss: 0.3999, training accuracy: 0.8176\n",
      "[Epoch 0][Batch 464][Samples 14880] time/batch: 0.255s training loss: 0.3999, training accuracy: 0.8177\n",
      "[Epoch 0][Batch 465][Samples 14912] time/batch: 0.262s training loss: 0.4000, training accuracy: 0.8175\n",
      "[Epoch 0][Batch 466][Samples 14944] time/batch: 0.258s training loss: 0.3997, training accuracy: 0.8177\n",
      "[Epoch 0][Batch 467][Samples 14976] time/batch: 0.262s training loss: 0.3994, training accuracy: 0.8179\n",
      "[Epoch 0][Batch 468][Samples 15008] time/batch: 0.257s training loss: 0.3989, training accuracy: 0.8183\n",
      "[Epoch 0][Batch 469][Samples 15040] time/batch: 0.257s training loss: 0.3988, training accuracy: 0.8184\n",
      "[Epoch 0][Batch 470][Samples 15072] time/batch: 0.258s training loss: 0.3990, training accuracy: 0.8184\n",
      "[Epoch 0][Batch 471][Samples 15104] time/batch: 0.268s training loss: 0.3990, training accuracy: 0.8185\n",
      "[Epoch 0][Batch 472][Samples 15136] time/batch: 0.260s training loss: 0.3996, training accuracy: 0.8179\n",
      "[Epoch 0][Batch 473][Samples 15168] time/batch: 0.254s training loss: 0.3996, training accuracy: 0.8177\n",
      "[Epoch 0][Batch 474][Samples 15200] time/batch: 0.260s training loss: 0.3997, training accuracy: 0.8176\n",
      "[Epoch 0][Batch 475][Samples 15232] time/batch: 0.263s training loss: 0.3997, training accuracy: 0.8176\n",
      "[Epoch 0][Batch 476][Samples 15264] time/batch: 0.259s training loss: 0.3994, training accuracy: 0.8177\n",
      "[Epoch 0][Batch 477][Samples 15296] time/batch: 0.259s training loss: 0.3993, training accuracy: 0.8179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 478][Samples 15328] time/batch: 0.262s training loss: 0.3992, training accuracy: 0.8180\n",
      "[Epoch 0][Batch 479][Samples 15360] time/batch: 0.257s training loss: 0.3987, training accuracy: 0.8182\n",
      "[Epoch 0][Batch 480][Samples 15392] time/batch: 0.258s training loss: 0.3985, training accuracy: 0.8183\n",
      "[Epoch 0][Batch 481][Samples 15424] time/batch: 0.260s training loss: 0.3980, training accuracy: 0.8185\n",
      "[Epoch 0][Batch 482][Samples 15456] time/batch: 0.258s training loss: 0.3978, training accuracy: 0.8186\n",
      "[Epoch 0][Batch 483][Samples 15488] time/batch: 0.269s training loss: 0.3978, training accuracy: 0.8186\n",
      "[Epoch 0][Batch 484][Samples 15520] time/batch: 0.259s training loss: 0.3980, training accuracy: 0.8187\n",
      "[Epoch 0][Batch 485][Samples 15552] time/batch: 0.257s training loss: 0.3977, training accuracy: 0.8189\n",
      "[Epoch 0][Batch 486][Samples 15584] time/batch: 0.261s training loss: 0.3972, training accuracy: 0.8190\n",
      "[Epoch 0][Batch 487][Samples 15616] time/batch: 0.262s training loss: 0.3970, training accuracy: 0.8192\n",
      "[Epoch 0][Batch 488][Samples 15648] time/batch: 0.260s training loss: 0.3971, training accuracy: 0.8193\n",
      "[Epoch 0][Batch 489][Samples 15680] time/batch: 0.257s training loss: 0.3971, training accuracy: 0.8194\n",
      "[Epoch 0][Batch 490][Samples 15712] time/batch: 0.260s training loss: 0.3968, training accuracy: 0.8195\n",
      "[Epoch 0][Batch 491][Samples 15744] time/batch: 0.256s training loss: 0.3969, training accuracy: 0.8194\n",
      "[Epoch 0][Batch 492][Samples 15776] time/batch: 0.267s training loss: 0.3971, training accuracy: 0.8194\n",
      "[Epoch 0][Batch 493][Samples 15808] time/batch: 0.261s training loss: 0.3970, training accuracy: 0.8195\n",
      "[Epoch 0][Batch 494][Samples 15840] time/batch: 0.259s training loss: 0.3968, training accuracy: 0.8196\n",
      "[Epoch 0][Batch 495][Samples 15872] time/batch: 0.261s training loss: 0.3967, training accuracy: 0.8197\n",
      "[Epoch 0][Batch 496][Samples 15904] time/batch: 0.257s training loss: 0.3965, training accuracy: 0.8197\n",
      "[Epoch 0][Batch 497][Samples 15936] time/batch: 0.261s training loss: 0.3961, training accuracy: 0.8199\n",
      "[Epoch 0][Batch 498][Samples 15968] time/batch: 0.267s training loss: 0.3958, training accuracy: 0.8200\n",
      "[Epoch 0][Batch 499][Samples 16000] time/batch: 0.265s training loss: 0.3959, training accuracy: 0.8198\n",
      "[Epoch 0][Batch 500][Samples 16032] time/batch: 0.256s training loss: 0.3958, training accuracy: 0.8199\n",
      "[Epoch 0][Batch 501][Samples 16064] time/batch: 0.265s training loss: 0.3957, training accuracy: 0.8199\n",
      "[Epoch 0][Batch 502][Samples 16096] time/batch: 0.258s training loss: 0.3955, training accuracy: 0.8200\n",
      "[Epoch 0][Batch 503][Samples 16128] time/batch: 0.266s training loss: 0.3953, training accuracy: 0.8200\n",
      "[Epoch 0][Batch 504][Samples 16160] time/batch: 0.269s training loss: 0.3952, training accuracy: 0.8200\n",
      "[Epoch 0][Batch 505][Samples 16192] time/batch: 0.268s training loss: 0.3949, training accuracy: 0.8202\n",
      "[Epoch 0][Batch 506][Samples 16224] time/batch: 0.264s training loss: 0.3948, training accuracy: 0.8203\n",
      "[Epoch 0][Batch 507][Samples 16256] time/batch: 0.261s training loss: 0.3946, training accuracy: 0.8204\n",
      "[Epoch 0][Batch 508][Samples 16288] time/batch: 0.272s training loss: 0.3945, training accuracy: 0.8205\n",
      "[Epoch 0][Batch 509][Samples 16320] time/batch: 0.256s training loss: 0.3942, training accuracy: 0.8206\n",
      "[Epoch 0][Batch 510][Samples 16352] time/batch: 0.273s training loss: 0.3942, training accuracy: 0.8206\n",
      "[Epoch 0][Batch 511][Samples 16384] time/batch: 0.258s training loss: 0.3938, training accuracy: 0.8207\n",
      "[Epoch 0][Batch 512][Samples 16416] time/batch: 0.274s training loss: 0.3938, training accuracy: 0.8208\n",
      "[Epoch 0][Batch 513][Samples 16448] time/batch: 0.261s training loss: 0.3936, training accuracy: 0.8210\n",
      "[Epoch 0][Batch 514][Samples 16480] time/batch: 0.256s training loss: 0.3935, training accuracy: 0.8211\n",
      "[Epoch 0][Batch 515][Samples 16512] time/batch: 0.257s training loss: 0.3936, training accuracy: 0.8211\n",
      "[Epoch 0][Batch 516][Samples 16544] time/batch: 0.260s training loss: 0.3937, training accuracy: 0.8211\n",
      "[Epoch 0][Batch 517][Samples 16576] time/batch: 0.258s training loss: 0.3932, training accuracy: 0.8214\n",
      "[Epoch 0][Batch 518][Samples 16608] time/batch: 0.256s training loss: 0.3933, training accuracy: 0.8214\n",
      "[Epoch 0][Batch 519][Samples 16640] time/batch: 0.261s training loss: 0.3932, training accuracy: 0.8214\n",
      "[Epoch 0][Batch 520][Samples 16672] time/batch: 0.257s training loss: 0.3930, training accuracy: 0.8214\n",
      "[Epoch 0][Batch 521][Samples 16704] time/batch: 0.263s training loss: 0.3929, training accuracy: 0.8216\n",
      "[Epoch 0][Batch 522][Samples 16736] time/batch: 0.259s training loss: 0.3925, training accuracy: 0.8218\n",
      "[Epoch 0][Batch 523][Samples 16768] time/batch: 0.259s training loss: 0.3923, training accuracy: 0.8220\n",
      "[Epoch 0][Batch 524][Samples 16800] time/batch: 0.261s training loss: 0.3921, training accuracy: 0.8220\n",
      "[Epoch 0][Batch 525][Samples 16832] time/batch: 0.268s training loss: 0.3920, training accuracy: 0.8221\n",
      "[Epoch 0][Batch 526][Samples 16864] time/batch: 0.256s training loss: 0.3916, training accuracy: 0.8222\n",
      "[Epoch 0][Batch 527][Samples 16896] time/batch: 0.257s training loss: 0.3919, training accuracy: 0.8220\n",
      "[Epoch 0][Batch 528][Samples 16928] time/batch: 0.273s training loss: 0.3917, training accuracy: 0.8221\n",
      "[Epoch 0][Batch 529][Samples 16960] time/batch: 0.271s training loss: 0.3914, training accuracy: 0.8222\n",
      "[Epoch 0][Batch 530][Samples 16992] time/batch: 0.267s training loss: 0.3914, training accuracy: 0.8223\n",
      "[Epoch 0][Batch 531][Samples 17024] time/batch: 0.275s training loss: 0.3915, training accuracy: 0.8222\n",
      "[Epoch 0][Batch 532][Samples 17056] time/batch: 0.262s training loss: 0.3912, training accuracy: 0.8223\n",
      "[Epoch 0][Batch 533][Samples 17088] time/batch: 0.264s training loss: 0.3911, training accuracy: 0.8224\n",
      "[Epoch 0][Batch 534][Samples 17120] time/batch: 0.269s training loss: 0.3911, training accuracy: 0.8224\n",
      "[Epoch 0][Batch 535][Samples 17152] time/batch: 0.267s training loss: 0.3914, training accuracy: 0.8223\n",
      "[Epoch 0][Batch 536][Samples 17184] time/batch: 0.272s training loss: 0.3911, training accuracy: 0.8225\n",
      "[Epoch 0][Batch 537][Samples 17216] time/batch: 0.323s training loss: 0.3910, training accuracy: 0.8225\n",
      "[Epoch 0][Batch 538][Samples 17248] time/batch: 0.258s training loss: 0.3910, training accuracy: 0.8225\n",
      "[Epoch 0][Batch 539][Samples 17280] time/batch: 0.261s training loss: 0.3910, training accuracy: 0.8226\n",
      "[Epoch 0][Batch 540][Samples 17312] time/batch: 0.259s training loss: 0.3910, training accuracy: 0.8226\n",
      "[Epoch 0][Batch 541][Samples 17344] time/batch: 0.264s training loss: 0.3909, training accuracy: 0.8226\n",
      "[Epoch 0][Batch 542][Samples 17376] time/batch: 0.265s training loss: 0.3907, training accuracy: 0.8227\n",
      "[Epoch 0][Batch 543][Samples 17408] time/batch: 0.259s training loss: 0.3905, training accuracy: 0.8227\n",
      "[Epoch 0][Batch 544][Samples 17440] time/batch: 0.258s training loss: 0.3908, training accuracy: 0.8227\n",
      "[Epoch 0][Batch 545][Samples 17472] time/batch: 0.263s training loss: 0.3906, training accuracy: 0.8227\n",
      "[Epoch 0][Batch 546][Samples 17504] time/batch: 0.264s training loss: 0.3903, training accuracy: 0.8228\n",
      "[Epoch 0][Batch 547][Samples 17536] time/batch: 0.267s training loss: 0.3901, training accuracy: 0.8228\n",
      "[Epoch 0][Batch 548][Samples 17568] time/batch: 0.267s training loss: 0.3899, training accuracy: 0.8229\n",
      "[Epoch 0][Batch 549][Samples 17600] time/batch: 0.273s training loss: 0.3899, training accuracy: 0.8228\n",
      "[Epoch 0][Batch 550][Samples 17632] time/batch: 0.261s training loss: 0.3899, training accuracy: 0.8229\n",
      "[Epoch 0][Batch 551][Samples 17664] time/batch: 0.255s training loss: 0.3901, training accuracy: 0.8229\n",
      "[Epoch 0][Batch 552][Samples 17696] time/batch: 0.262s training loss: 0.3905, training accuracy: 0.8227\n",
      "[Epoch 0][Batch 553][Samples 17728] time/batch: 0.255s training loss: 0.3904, training accuracy: 0.8227\n",
      "[Epoch 0][Batch 554][Samples 17760] time/batch: 0.262s training loss: 0.3901, training accuracy: 0.8229\n",
      "[Epoch 0][Batch 555][Samples 17792] time/batch: 0.263s training loss: 0.3897, training accuracy: 0.8232\n",
      "[Epoch 0][Batch 556][Samples 17824] time/batch: 0.263s training loss: 0.3894, training accuracy: 0.8234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 557][Samples 17856] time/batch: 0.256s training loss: 0.3891, training accuracy: 0.8236\n",
      "[Epoch 0][Batch 558][Samples 17888] time/batch: 0.258s training loss: 0.3891, training accuracy: 0.8237\n",
      "[Epoch 0][Batch 559][Samples 17920] time/batch: 0.256s training loss: 0.3890, training accuracy: 0.8238\n",
      "[Epoch 0][Batch 560][Samples 17952] time/batch: 0.264s training loss: 0.3889, training accuracy: 0.8239\n",
      "[Epoch 0][Batch 561][Samples 17984] time/batch: 0.256s training loss: 0.3888, training accuracy: 0.8238\n",
      "[Epoch 0][Batch 562][Samples 18016] time/batch: 0.260s training loss: 0.3890, training accuracy: 0.8239\n",
      "[Epoch 0][Batch 563][Samples 18048] time/batch: 0.259s training loss: 0.3887, training accuracy: 0.8240\n",
      "[Epoch 0][Batch 564][Samples 18080] time/batch: 0.262s training loss: 0.3884, training accuracy: 0.8240\n",
      "[Epoch 0][Batch 565][Samples 18112] time/batch: 0.257s training loss: 0.3884, training accuracy: 0.8240\n",
      "[Epoch 0][Batch 566][Samples 18144] time/batch: 0.256s training loss: 0.3882, training accuracy: 0.8242\n",
      "[Epoch 0][Batch 567][Samples 18176] time/batch: 0.260s training loss: 0.3879, training accuracy: 0.8243\n",
      "[Epoch 0][Batch 568][Samples 18208] time/batch: 0.257s training loss: 0.3878, training accuracy: 0.8244\n",
      "[Epoch 0][Batch 569][Samples 18240] time/batch: 0.261s training loss: 0.3875, training accuracy: 0.8246\n",
      "[Epoch 0][Batch 570][Samples 18272] time/batch: 0.271s training loss: 0.3877, training accuracy: 0.8245\n",
      "[Epoch 0][Batch 571][Samples 18304] time/batch: 0.260s training loss: 0.3873, training accuracy: 0.8247\n",
      "[Epoch 0][Batch 572][Samples 18336] time/batch: 0.258s training loss: 0.3870, training accuracy: 0.8248\n",
      "[Epoch 0][Batch 573][Samples 18368] time/batch: 0.261s training loss: 0.3872, training accuracy: 0.8247\n",
      "[Epoch 0][Batch 574][Samples 18400] time/batch: 0.256s training loss: 0.3872, training accuracy: 0.8247\n",
      "[Epoch 0][Batch 575][Samples 18432] time/batch: 0.255s training loss: 0.3869, training accuracy: 0.8248\n",
      "[Epoch 0][Batch 576][Samples 18464] time/batch: 0.271s training loss: 0.3869, training accuracy: 0.8248\n",
      "[Epoch 0][Batch 577][Samples 18496] time/batch: 0.255s training loss: 0.3867, training accuracy: 0.8250\n",
      "[Epoch 0][Batch 578][Samples 18528] time/batch: 0.257s training loss: 0.3865, training accuracy: 0.8250\n",
      "[Epoch 0][Batch 579][Samples 18560] time/batch: 0.265s training loss: 0.3865, training accuracy: 0.8250\n",
      "[Epoch 0][Batch 580][Samples 18592] time/batch: 0.259s training loss: 0.3863, training accuracy: 0.8251\n",
      "[Epoch 0][Batch 581][Samples 18624] time/batch: 0.264s training loss: 0.3862, training accuracy: 0.8252\n",
      "[Epoch 0][Batch 582][Samples 18656] time/batch: 0.257s training loss: 0.3859, training accuracy: 0.8253\n",
      "[Epoch 0][Batch 583][Samples 18688] time/batch: 0.258s training loss: 0.3858, training accuracy: 0.8253\n",
      "[Epoch 0][Batch 584][Samples 18720] time/batch: 0.269s training loss: 0.3855, training accuracy: 0.8255\n",
      "[Epoch 0][Batch 585][Samples 18752] time/batch: 0.267s training loss: 0.3856, training accuracy: 0.8254\n",
      "[Epoch 0][Batch 586][Samples 18784] time/batch: 0.258s training loss: 0.3854, training accuracy: 0.8255\n",
      "[Epoch 0][Batch 587][Samples 18816] time/batch: 0.259s training loss: 0.3852, training accuracy: 0.8255\n",
      "[Epoch 0][Batch 588][Samples 18848] time/batch: 0.256s training loss: 0.3852, training accuracy: 0.8254\n",
      "[Epoch 0][Batch 589][Samples 18880] time/batch: 0.262s training loss: 0.3849, training accuracy: 0.8256\n",
      "[Epoch 0][Batch 590][Samples 18912] time/batch: 0.258s training loss: 0.3849, training accuracy: 0.8256\n",
      "[Epoch 0][Batch 591][Samples 18944] time/batch: 0.264s training loss: 0.3848, training accuracy: 0.8257\n",
      "[Epoch 0][Batch 592][Samples 18976] time/batch: 0.259s training loss: 0.3851, training accuracy: 0.8256\n",
      "[Epoch 0][Batch 593][Samples 19008] time/batch: 0.255s training loss: 0.3850, training accuracy: 0.8257\n",
      "[Epoch 0][Batch 594][Samples 19040] time/batch: 0.260s training loss: 0.3850, training accuracy: 0.8257\n",
      "[Epoch 0][Batch 595][Samples 19072] time/batch: 0.273s training loss: 0.3847, training accuracy: 0.8257\n",
      "[Epoch 0][Batch 596][Samples 19104] time/batch: 0.256s training loss: 0.3845, training accuracy: 0.8258\n",
      "[Epoch 0][Batch 597][Samples 19136] time/batch: 0.262s training loss: 0.3841, training accuracy: 0.8260\n",
      "[Epoch 0][Batch 598][Samples 19168] time/batch: 0.257s training loss: 0.3842, training accuracy: 0.8260\n",
      "[Epoch 0][Batch 599][Samples 19200] time/batch: 0.260s training loss: 0.3841, training accuracy: 0.8260\n",
      "[Epoch 0][Batch 600][Samples 19232] time/batch: 0.271s training loss: 0.3838, training accuracy: 0.8261\n",
      "[Epoch 0][Batch 601][Samples 19264] time/batch: 0.256s training loss: 0.3835, training accuracy: 0.8262\n",
      "[Epoch 0][Batch 602][Samples 19296] time/batch: 0.257s training loss: 0.3836, training accuracy: 0.8262\n",
      "[Epoch 0][Batch 603][Samples 19328] time/batch: 0.256s training loss: 0.3834, training accuracy: 0.8263\n",
      "[Epoch 0][Batch 604][Samples 19360] time/batch: 0.263s training loss: 0.3831, training accuracy: 0.8264\n",
      "[Epoch 0][Batch 605][Samples 19392] time/batch: 0.260s training loss: 0.3832, training accuracy: 0.8265\n",
      "[Epoch 0][Batch 606][Samples 19424] time/batch: 0.268s training loss: 0.3831, training accuracy: 0.8265\n",
      "[Epoch 0][Batch 607][Samples 19456] time/batch: 0.257s training loss: 0.3832, training accuracy: 0.8264\n",
      "[Epoch 0][Batch 608][Samples 19488] time/batch: 0.263s training loss: 0.3830, training accuracy: 0.8265\n",
      "[Epoch 0][Batch 609][Samples 19520] time/batch: 0.255s training loss: 0.3829, training accuracy: 0.8265\n",
      "[Epoch 0][Batch 610][Samples 19552] time/batch: 0.262s training loss: 0.3829, training accuracy: 0.8264\n",
      "[Epoch 0][Batch 611][Samples 19584] time/batch: 0.271s training loss: 0.3826, training accuracy: 0.8265\n",
      "[Epoch 0][Batch 612][Samples 19616] time/batch: 0.275s training loss: 0.3825, training accuracy: 0.8267\n",
      "[Epoch 0][Batch 613][Samples 19648] time/batch: 0.273s training loss: 0.3825, training accuracy: 0.8266\n",
      "[Epoch 0][Batch 614][Samples 19680] time/batch: 0.266s training loss: 0.3822, training accuracy: 0.8268\n",
      "[Epoch 0][Batch 615][Samples 19712] time/batch: 0.263s training loss: 0.3818, training accuracy: 0.8270\n",
      "[Epoch 0][Batch 616][Samples 19744] time/batch: 0.266s training loss: 0.3816, training accuracy: 0.8271\n",
      "[Epoch 0][Batch 617][Samples 19776] time/batch: 0.271s training loss: 0.3813, training accuracy: 0.8273\n",
      "[Epoch 0][Batch 618][Samples 19808] time/batch: 0.260s training loss: 0.3811, training accuracy: 0.8275\n",
      "[Epoch 0][Batch 619][Samples 19840] time/batch: 0.255s training loss: 0.3807, training accuracy: 0.8276\n",
      "[Epoch 0][Batch 620][Samples 19872] time/batch: 0.259s training loss: 0.3807, training accuracy: 0.8277\n",
      "[Epoch 0][Batch 621][Samples 19904] time/batch: 0.272s training loss: 0.3805, training accuracy: 0.8279\n",
      "[Epoch 0][Batch 622][Samples 19936] time/batch: 0.259s training loss: 0.3804, training accuracy: 0.8279\n",
      "[Epoch 0][Batch 623][Samples 19968] time/batch: 0.273s training loss: 0.3804, training accuracy: 0.8278\n",
      "[Epoch 0][Batch 624][Samples 20000] time/batch: 0.259s training loss: 0.3802, training accuracy: 0.8279\n",
      "[Epoch 0][Batch 625][Samples 20032] time/batch: 0.266s training loss: 0.3799, training accuracy: 0.8281\n",
      "[Epoch 0][Batch 626][Samples 20064] time/batch: 0.267s training loss: 0.3796, training accuracy: 0.8282\n",
      "[Epoch 0][Batch 627][Samples 20096] time/batch: 0.267s training loss: 0.3794, training accuracy: 0.8283\n",
      "[Epoch 0][Batch 628][Samples 20128] time/batch: 0.271s training loss: 0.3796, training accuracy: 0.8283\n",
      "[Epoch 0][Batch 629][Samples 20160] time/batch: 0.266s training loss: 0.3798, training accuracy: 0.8283\n",
      "[Epoch 0][Batch 630][Samples 20192] time/batch: 0.265s training loss: 0.3800, training accuracy: 0.8281\n",
      "[Epoch 0][Batch 631][Samples 20224] time/batch: 0.269s training loss: 0.3802, training accuracy: 0.8281\n",
      "[Epoch 0][Batch 632][Samples 20256] time/batch: 0.259s training loss: 0.3802, training accuracy: 0.8281\n",
      "[Epoch 0][Batch 633][Samples 20288] time/batch: 0.262s training loss: 0.3801, training accuracy: 0.8281\n",
      "[Epoch 0][Batch 634][Samples 20320] time/batch: 0.260s training loss: 0.3797, training accuracy: 0.8283\n",
      "[Epoch 0][Batch 635][Samples 20352] time/batch: 0.264s training loss: 0.3795, training accuracy: 0.8284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 636][Samples 20384] time/batch: 0.256s training loss: 0.3795, training accuracy: 0.8283\n",
      "[Epoch 0][Batch 637][Samples 20416] time/batch: 0.260s training loss: 0.3794, training accuracy: 0.8284\n",
      "[Epoch 0][Batch 638][Samples 20448] time/batch: 0.256s training loss: 0.3789, training accuracy: 0.8286\n",
      "[Epoch 0][Batch 639][Samples 20480] time/batch: 0.261s training loss: 0.3788, training accuracy: 0.8288\n",
      "[Epoch 0][Batch 640][Samples 20512] time/batch: 0.258s training loss: 0.3785, training accuracy: 0.8289\n",
      "[Epoch 0][Batch 641][Samples 20544] time/batch: 0.276s training loss: 0.3782, training accuracy: 0.8290\n",
      "[Epoch 0][Batch 642][Samples 20576] time/batch: 0.271s training loss: 0.3781, training accuracy: 0.8291\n",
      "[Epoch 0][Batch 643][Samples 20608] time/batch: 0.256s training loss: 0.3781, training accuracy: 0.8290\n",
      "[Epoch 0][Batch 644][Samples 20640] time/batch: 0.258s training loss: 0.3778, training accuracy: 0.8291\n",
      "[Epoch 0][Batch 645][Samples 20672] time/batch: 0.261s training loss: 0.3775, training accuracy: 0.8292\n",
      "[Epoch 0][Batch 646][Samples 20704] time/batch: 0.272s training loss: 0.3772, training accuracy: 0.8293\n",
      "[Epoch 0][Batch 647][Samples 20736] time/batch: 0.255s training loss: 0.3768, training accuracy: 0.8295\n",
      "[Epoch 0][Batch 648][Samples 20768] time/batch: 0.259s training loss: 0.3767, training accuracy: 0.8295\n",
      "[Epoch 0][Batch 649][Samples 20800] time/batch: 0.259s training loss: 0.3764, training accuracy: 0.8296\n",
      "[Epoch 0][Batch 650][Samples 20832] time/batch: 0.264s training loss: 0.3766, training accuracy: 0.8295\n",
      "[Epoch 0][Batch 651][Samples 20864] time/batch: 0.258s training loss: 0.3767, training accuracy: 0.8294\n",
      "[Epoch 0][Batch 652][Samples 20896] time/batch: 0.263s training loss: 0.3766, training accuracy: 0.8294\n",
      "[Epoch 0][Batch 653][Samples 20928] time/batch: 0.261s training loss: 0.3764, training accuracy: 0.8295\n",
      "[Epoch 0][Batch 654][Samples 20960] time/batch: 0.275s training loss: 0.3761, training accuracy: 0.8296\n",
      "[Epoch 0][Batch 655][Samples 20992] time/batch: 0.257s training loss: 0.3761, training accuracy: 0.8297\n",
      "[Epoch 0][Batch 656][Samples 21024] time/batch: 0.255s training loss: 0.3760, training accuracy: 0.8297\n",
      "[Epoch 0][Batch 657][Samples 21056] time/batch: 0.261s training loss: 0.3757, training accuracy: 0.8298\n",
      "[Epoch 0][Batch 658][Samples 21088] time/batch: 0.258s training loss: 0.3754, training accuracy: 0.8300\n",
      "[Epoch 0][Batch 659][Samples 21120] time/batch: 0.260s training loss: 0.3751, training accuracy: 0.8301\n",
      "[Epoch 0][Batch 660][Samples 21152] time/batch: 0.270s training loss: 0.3751, training accuracy: 0.8301\n",
      "[Epoch 0][Batch 661][Samples 21184] time/batch: 0.275s training loss: 0.3750, training accuracy: 0.8302\n",
      "[Epoch 0][Batch 662][Samples 21216] time/batch: 0.269s training loss: 0.3748, training accuracy: 0.8303\n",
      "[Epoch 0][Batch 663][Samples 21248] time/batch: 0.272s training loss: 0.3747, training accuracy: 0.8304\n",
      "[Epoch 0][Batch 664][Samples 21280] time/batch: 0.257s training loss: 0.3745, training accuracy: 0.8305\n",
      "[Epoch 0][Batch 665][Samples 21312] time/batch: 0.260s training loss: 0.3745, training accuracy: 0.8305\n",
      "[Epoch 0][Batch 666][Samples 21344] time/batch: 0.270s training loss: 0.3748, training accuracy: 0.8304\n",
      "[Epoch 0][Batch 667][Samples 21376] time/batch: 0.257s training loss: 0.3747, training accuracy: 0.8304\n",
      "[Epoch 0][Batch 668][Samples 21408] time/batch: 0.266s training loss: 0.3743, training accuracy: 0.8306\n",
      "[Epoch 0][Batch 669][Samples 21440] time/batch: 0.264s training loss: 0.3742, training accuracy: 0.8307\n",
      "[Epoch 0][Batch 670][Samples 21472] time/batch: 0.260s training loss: 0.3742, training accuracy: 0.8307\n",
      "[Epoch 0][Batch 671][Samples 21504] time/batch: 0.269s training loss: 0.3740, training accuracy: 0.8307\n",
      "[Epoch 0][Batch 672][Samples 21536] time/batch: 0.259s training loss: 0.3738, training accuracy: 0.8307\n",
      "[Epoch 0][Batch 673][Samples 21568] time/batch: 0.262s training loss: 0.3736, training accuracy: 0.8309\n",
      "[Epoch 0][Batch 674][Samples 21600] time/batch: 0.268s training loss: 0.3733, training accuracy: 0.8310\n",
      "[Epoch 0][Batch 675][Samples 21632] time/batch: 0.262s training loss: 0.3731, training accuracy: 0.8311\n",
      "[Epoch 0][Batch 676][Samples 21664] time/batch: 0.261s training loss: 0.3730, training accuracy: 0.8311\n",
      "[Epoch 0][Batch 677][Samples 21696] time/batch: 0.266s training loss: 0.3729, training accuracy: 0.8311\n",
      "[Epoch 0][Batch 678][Samples 21728] time/batch: 0.270s training loss: 0.3726, training accuracy: 0.8312\n",
      "[Epoch 0][Batch 679][Samples 21760] time/batch: 0.263s training loss: 0.3726, training accuracy: 0.8313\n",
      "[Epoch 0][Batch 680][Samples 21792] time/batch: 0.258s training loss: 0.3723, training accuracy: 0.8314\n",
      "[Epoch 0][Batch 681][Samples 21824] time/batch: 0.256s training loss: 0.3723, training accuracy: 0.8313\n",
      "[Epoch 0][Batch 682][Samples 21856] time/batch: 0.259s training loss: 0.3720, training accuracy: 0.8314\n",
      "[Epoch 0][Batch 683][Samples 21888] time/batch: 0.263s training loss: 0.3719, training accuracy: 0.8315\n",
      "[Epoch 0][Batch 684][Samples 21920] time/batch: 0.257s training loss: 0.3719, training accuracy: 0.8315\n",
      "[Epoch 0][Batch 685][Samples 21952] time/batch: 0.262s training loss: 0.3722, training accuracy: 0.8315\n",
      "[Epoch 0][Batch 686][Samples 21984] time/batch: 0.269s training loss: 0.3722, training accuracy: 0.8315\n",
      "[Epoch 0][Batch 687][Samples 22016] time/batch: 0.261s training loss: 0.3720, training accuracy: 0.8315\n",
      "[Epoch 0][Batch 688][Samples 22048] time/batch: 0.258s training loss: 0.3720, training accuracy: 0.8316\n",
      "[Epoch 0][Batch 689][Samples 22080] time/batch: 0.267s training loss: 0.3719, training accuracy: 0.8317\n",
      "[Epoch 0][Batch 690][Samples 22112] time/batch: 0.260s training loss: 0.3718, training accuracy: 0.8318\n",
      "[Epoch 0][Batch 691][Samples 22144] time/batch: 0.258s training loss: 0.3717, training accuracy: 0.8318\n",
      "[Epoch 0][Batch 692][Samples 22176] time/batch: 0.261s training loss: 0.3715, training accuracy: 0.8319\n",
      "[Epoch 0][Batch 693][Samples 22208] time/batch: 0.267s training loss: 0.3718, training accuracy: 0.8319\n",
      "[Epoch 0][Batch 694][Samples 22240] time/batch: 0.260s training loss: 0.3718, training accuracy: 0.8320\n",
      "[Epoch 0][Batch 695][Samples 22272] time/batch: 0.264s training loss: 0.3720, training accuracy: 0.8319\n",
      "[Epoch 0][Batch 696][Samples 22304] time/batch: 0.260s training loss: 0.3720, training accuracy: 0.8319\n",
      "[Epoch 0][Batch 697][Samples 22336] time/batch: 0.263s training loss: 0.3718, training accuracy: 0.8321\n",
      "[Epoch 0][Batch 698][Samples 22368] time/batch: 0.259s training loss: 0.3715, training accuracy: 0.8322\n",
      "[Epoch 0][Batch 699][Samples 22400] time/batch: 0.257s training loss: 0.3712, training accuracy: 0.8324\n",
      "[Epoch 0][Batch 700][Samples 22432] time/batch: 0.266s training loss: 0.3713, training accuracy: 0.8324\n",
      "[Epoch 0][Batch 701][Samples 22464] time/batch: 0.268s training loss: 0.3709, training accuracy: 0.8326\n",
      "[Epoch 0][Batch 702][Samples 22496] time/batch: 0.272s training loss: 0.3709, training accuracy: 0.8326\n",
      "[Epoch 0][Batch 703][Samples 22528] time/batch: 0.261s training loss: 0.3707, training accuracy: 0.8327\n",
      "[Epoch 0][Batch 704][Samples 22560] time/batch: 0.261s training loss: 0.3704, training accuracy: 0.8328\n",
      "[Epoch 0][Batch 705][Samples 22592] time/batch: 0.259s training loss: 0.3702, training accuracy: 0.8330\n",
      "[Epoch 0][Batch 706][Samples 22624] time/batch: 0.258s training loss: 0.3702, training accuracy: 0.8331\n",
      "[Epoch 0][Batch 707][Samples 22656] time/batch: 0.256s training loss: 0.3700, training accuracy: 0.8332\n",
      "[Epoch 0][Batch 708][Samples 22688] time/batch: 0.262s training loss: 0.3699, training accuracy: 0.8332\n",
      "[Epoch 0][Batch 709][Samples 22720] time/batch: 0.256s training loss: 0.3698, training accuracy: 0.8332\n",
      "[Epoch 0][Batch 710][Samples 22752] time/batch: 0.261s training loss: 0.3695, training accuracy: 0.8333\n",
      "[Epoch 0][Batch 711][Samples 22784] time/batch: 0.259s training loss: 0.3692, training accuracy: 0.8335\n",
      "[Epoch 0][Batch 712][Samples 22816] time/batch: 0.259s training loss: 0.3691, training accuracy: 0.8337\n",
      "[Epoch 0][Batch 713][Samples 22848] time/batch: 0.258s training loss: 0.3689, training accuracy: 0.8338\n",
      "[Epoch 0][Batch 714][Samples 22880] time/batch: 0.257s training loss: 0.3686, training accuracy: 0.8340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0][Batch 715][Samples 22912] time/batch: 0.259s training loss: 0.3683, training accuracy: 0.8340\n",
      "[Epoch 0][Batch 716][Samples 22944] time/batch: 0.262s training loss: 0.3680, training accuracy: 0.8342\n",
      "[Epoch 0][Batch 717][Samples 22976] time/batch: 0.256s training loss: 0.3678, training accuracy: 0.8344\n",
      "[Epoch 0][Batch 718][Samples 23008] time/batch: 0.260s training loss: 0.3678, training accuracy: 0.8344\n",
      "[Epoch 0][Batch 719][Samples 23040] time/batch: 0.261s training loss: 0.3679, training accuracy: 0.8344\n",
      "[Epoch 0][Batch 720][Samples 23072] time/batch: 0.266s training loss: 0.3678, training accuracy: 0.8343\n",
      "[Epoch 0][Batch 721][Samples 23104] time/batch: 0.258s training loss: 0.3679, training accuracy: 0.8342\n",
      "[Epoch 0][Batch 722][Samples 23136] time/batch: 0.278s training loss: 0.3677, training accuracy: 0.8343\n",
      "[Epoch 0][Batch 723][Samples 23168] time/batch: 0.261s training loss: 0.3675, training accuracy: 0.8344\n",
      "[Epoch 0][Batch 724][Samples 23200] time/batch: 0.260s training loss: 0.3673, training accuracy: 0.8345\n",
      "[Epoch 0][Batch 725][Samples 23232] time/batch: 0.262s training loss: 0.3670, training accuracy: 0.8347\n",
      "[Epoch 0][Batch 726][Samples 23264] time/batch: 0.256s training loss: 0.3670, training accuracy: 0.8346\n",
      "[Epoch 0][Batch 727][Samples 23296] time/batch: 0.260s training loss: 0.3669, training accuracy: 0.8347\n",
      "[Epoch 0][Batch 728][Samples 23328] time/batch: 0.257s training loss: 0.3667, training accuracy: 0.8347\n",
      "[Epoch 0][Batch 729][Samples 23360] time/batch: 0.257s training loss: 0.3669, training accuracy: 0.8348\n",
      "[Epoch 0][Batch 730][Samples 23392] time/batch: 0.261s training loss: 0.3672, training accuracy: 0.8346\n",
      "[Epoch 0][Batch 731][Samples 23424] time/batch: 0.256s training loss: 0.3669, training accuracy: 0.8348\n",
      "[Epoch 0][Batch 732][Samples 23456] time/batch: 0.260s training loss: 0.3668, training accuracy: 0.8348\n",
      "[Epoch 0][Batch 733][Samples 23488] time/batch: 0.256s training loss: 0.3667, training accuracy: 0.8349\n",
      "[Epoch 0][Batch 734][Samples 23520] time/batch: 0.262s training loss: 0.3666, training accuracy: 0.8349\n",
      "[Epoch 0][Batch 735][Samples 23552] time/batch: 0.260s training loss: 0.3664, training accuracy: 0.8350\n",
      "[Epoch 0][Batch 736][Samples 23584] time/batch: 0.263s training loss: 0.3666, training accuracy: 0.8350\n",
      "[Epoch 0][Batch 737][Samples 23616] time/batch: 0.268s training loss: 0.3666, training accuracy: 0.8350\n",
      "[Epoch 0][Batch 738][Samples 23648] time/batch: 0.267s training loss: 0.3665, training accuracy: 0.8350\n",
      "[Epoch 0][Batch 739][Samples 23680] time/batch: 0.256s training loss: 0.3662, training accuracy: 0.8352\n",
      "[Epoch 0][Batch 740][Samples 23712] time/batch: 0.264s training loss: 0.3659, training accuracy: 0.8353\n",
      "[Epoch 0][Batch 741][Samples 23744] time/batch: 0.256s training loss: 0.3657, training accuracy: 0.8354\n",
      "[Epoch 0][Batch 742][Samples 23776] time/batch: 0.274s training loss: 0.3656, training accuracy: 0.8354\n",
      "[Epoch 0][Batch 743][Samples 23808] time/batch: 0.267s training loss: 0.3655, training accuracy: 0.8353\n",
      "[Epoch 0][Batch 744][Samples 23840] time/batch: 0.257s training loss: 0.3656, training accuracy: 0.8353\n",
      "[Epoch 0][Batch 745][Samples 23872] time/batch: 0.264s training loss: 0.3656, training accuracy: 0.8354\n",
      "[Epoch 0][Batch 746][Samples 23904] time/batch: 0.267s training loss: 0.3655, training accuracy: 0.8354\n",
      "[Epoch 0][Batch 747][Samples 23936] time/batch: 0.272s training loss: 0.3654, training accuracy: 0.8354\n",
      "[Epoch 0][Batch 748][Samples 23968] time/batch: 0.264s training loss: 0.3657, training accuracy: 0.8354\n",
      "[Epoch 0][Batch 749][Samples 24000] time/batch: 0.262s training loss: 0.3657, training accuracy: 0.8354\n",
      "[Epoch 0][Batch 750][Samples 24032] time/batch: 0.257s training loss: 0.3654, training accuracy: 0.8356\n",
      "[Epoch 0][Batch 751][Samples 24064] time/batch: 0.261s training loss: 0.3652, training accuracy: 0.8357\n",
      "[Epoch 0][Batch 752][Samples 24096] time/batch: 0.257s training loss: 0.3652, training accuracy: 0.8357\n",
      "[Epoch 0][Batch 753][Samples 24128] time/batch: 0.255s training loss: 0.3650, training accuracy: 0.8358\n",
      "[Epoch 0][Batch 754][Samples 24160] time/batch: 0.260s training loss: 0.3650, training accuracy: 0.8357\n",
      "[Epoch 0][Batch 755][Samples 24192] time/batch: 0.259s training loss: 0.3648, training accuracy: 0.8358\n",
      "[Epoch 0][Batch 756][Samples 24224] time/batch: 0.260s training loss: 0.3645, training accuracy: 0.8360\n",
      "[Epoch 0][Batch 757][Samples 24256] time/batch: 0.255s training loss: 0.3645, training accuracy: 0.8360\n",
      "[Epoch 0][Batch 758][Samples 24288] time/batch: 0.271s training loss: 0.3643, training accuracy: 0.8361\n",
      "[Epoch 0][Batch 759][Samples 24320] time/batch: 0.269s training loss: 0.3642, training accuracy: 0.8362\n",
      "[Epoch 0][Batch 760][Samples 24352] time/batch: 0.261s training loss: 0.3642, training accuracy: 0.8363\n",
      "[Epoch 0][Batch 761][Samples 24384] time/batch: 0.275s training loss: 0.3641, training accuracy: 0.8365\n",
      "[Epoch 0][Batch 762][Samples 24416] time/batch: 0.272s training loss: 0.3639, training accuracy: 0.8365\n",
      "[Epoch 0][Batch 763][Samples 24448] time/batch: 0.267s training loss: 0.3637, training accuracy: 0.8366\n",
      "[Epoch 0][Batch 764][Samples 24480] time/batch: 0.265s training loss: 0.3638, training accuracy: 0.8366\n",
      "[Epoch 0][Batch 765][Samples 24512] time/batch: 0.266s training loss: 0.3637, training accuracy: 0.8367\n",
      "[Epoch 0][Batch 766][Samples 24544] time/batch: 0.268s training loss: 0.3635, training accuracy: 0.8368\n",
      "[Epoch 0][Batch 767][Samples 24576] time/batch: 0.257s training loss: 0.3634, training accuracy: 0.8368\n",
      "[Epoch 0][Batch 768][Samples 24608] time/batch: 0.263s training loss: 0.3633, training accuracy: 0.8368\n",
      "[Epoch 0][Batch 769][Samples 24640] time/batch: 0.260s training loss: 0.3631, training accuracy: 0.8369\n",
      "[Epoch 0][Batch 770][Samples 24672] time/batch: 0.271s training loss: 0.3632, training accuracy: 0.8369\n",
      "[Epoch 0][Batch 771][Samples 24704] time/batch: 0.258s training loss: 0.3630, training accuracy: 0.8370\n",
      "[Epoch 0][Batch 772][Samples 24736] time/batch: 0.270s training loss: 0.3629, training accuracy: 0.8371\n",
      "[Epoch 0][Batch 773][Samples 24768] time/batch: 0.255s training loss: 0.3627, training accuracy: 0.8372\n",
      "[Epoch 0][Batch 774][Samples 24800] time/batch: 0.260s training loss: 0.3627, training accuracy: 0.8373\n",
      "[Epoch 0][Batch 775][Samples 24832] time/batch: 0.266s training loss: 0.3626, training accuracy: 0.8373\n",
      "[Epoch 0][Batch 776][Samples 24864] time/batch: 0.262s training loss: 0.3626, training accuracy: 0.8372\n",
      "[Epoch 0][Batch 777][Samples 24896] time/batch: 0.266s training loss: 0.3625, training accuracy: 0.8372\n",
      "[Epoch 0][Batch 778][Samples 24928] time/batch: 0.258s training loss: 0.3626, training accuracy: 0.8372\n",
      "[Epoch 0][Batch 779][Samples 24960] time/batch: 0.261s training loss: 0.3625, training accuracy: 0.8372\n",
      "[Epoch 0][Batch 780][Samples 24992] time/batch: 0.260s training loss: 0.3626, training accuracy: 0.8372\n",
      "[Epoch 0][Batch 781][Samples 25000] time/batch: 0.138s training loss: 0.3625, training accuracy: 0.8373\n",
      "[Epoch 0] Finished in 336.362s, training loss: 0.3625, training accuracy: 0.8373\n",
      "Train finished using total 336s with 1 epochs. training loss: 0.3625, training accuracy: 0.8373\n"
     ]
    }
   ],
   "source": [
    "trainer = mx.gluon.Trainer(net.collect_params(), 'bertadam',\n",
    "                        {'learning_rate': lr, 'wd':0.01})\n",
    "loss_fn = mx.gluon.loss.SoftmaxCELoss()\n",
    "metrics = [mx.metric.Loss(), mx.metric.Accuracy()]\n",
    "lr_handler = MyLearningRateHandler(trainer=trainer, num_warmup_steps=50, lr=5e-5,\n",
    "                                   num_train_steps = len(train_data) * num_epochs)\n",
    "logging_handler = LoggingHandler(train_metrics=metrics, verbose=LoggingHandler.LOG_PER_BATCH)\n",
    "event_handlers = [lr_handler, logging_handler]\n",
    "\n",
    "est = MyEstimator(net=net, loss=loss_fn, metrics=metrics, trainer=trainer, context=ctx)\n",
    "est.fit(train_data=train_data, epochs=num_epochs, event_handlers=event_handlers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.879\n"
     ]
    }
   ],
   "source": [
    "val_metric = mx.metric.Accuracy()\n",
    "est.evaluate(test_data, val_metrics=[val_metric])\n",
    "print('Validation {} = {}'.format(*val_metric.get()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(net, ctx, transform, sentence):\n",
    "    ctx = ctx[0] if isinstance(ctx, list) else ctx\n",
    "    inputs, seq_len, token_types = transform([sentence])\n",
    "    inputs = mx.nd.array([inputs], ctx=ctx)\n",
    "    token_types = mx.nd.array([token_types], ctx=ctx)\n",
    "    seq_len = mx.nd.array([seq_len], ctx=ctx)\n",
    "    out = net(inputs, token_types, seq_len)\n",
    "    label = mx.nd.argmax(out, axis=1)\n",
    "    return 'positive' if label.asscalar() == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, ctx, transform, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deploy on SageMaker\n",
    "\n",
    "1. Model parameters\n",
    "2. Code with data pre-processing and model inference\n",
    "3. A docker container with dependencies installed\n",
    "4. Launch a serving end-point with SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1. Save Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# save parameters, model definition and vocabulary in a zip file\n",
    "net.export('checkpoint')\n",
    "with open('vocab.json', 'w') as f:\n",
    "    f.write(vocabulary.to_json())\n",
    "import tarfile\n",
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"checkpoint-0000.params\") \n",
    "    tar.add(\"checkpoint-symbol.json\") \n",
    "    tar.add(\"vocab.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. the Code for Inference\n",
    "\n",
    "Two functions: \n",
    "1. model_fn() to load model parameters\n",
    "2. transform_fn() to run model inference given an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile serve.py\n",
    "import json, logging, warnings\n",
    "import gluonnlp as nlp\n",
    "import mxnet as mx\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Load the gluon model. Called once when hosting service starts.\n",
    "    :param: model_dir The directory where model files are stored.\n",
    "    :return: a Gluon model, and the vocabulary\n",
    "    \"\"\"\n",
    "    prefix = 'checkpoint'\n",
    "    net = mx.gluon.nn.SymbolBlock.imports(prefix + '-symbol.json',\n",
    "                                          ['data0', 'data1', 'data2'],\n",
    "                                          prefix + '-0000.params')\n",
    "    net.load_parameters('%s/' % model_dir + prefix + '-0000.params',\n",
    "                        ctx=mx.cpu())\n",
    "    vocab_json = open('%s/vocab.json' % model_dir).read()\n",
    "    vocab = nlp.Vocab.from_json(vocab_json)\n",
    "    tokenizer = nlp.data.BERTTokenizer(vocab)\n",
    "    transform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length=128,\n",
    "                                               pair=False, pad=False)\n",
    "    return net, vocab, transform\n",
    "\n",
    "\n",
    "def transform_fn(model, data, input_content_type, output_content_type):\n",
    "    \"\"\"\n",
    "    Transform a request using the Gluon model. Called once per request.\n",
    "    :param model: The Gluon model and the vocab\n",
    "    :param data: The request payload.\n",
    "    :param input_content_type: The request content type.\n",
    "    :param output_content_type: The (desired) response content type.\n",
    "    :return: response payload and content type.\n",
    "    \"\"\"\n",
    "    # we can use content types to vary input/output handling, but\n",
    "    # here we just assume json for both\n",
    "    net, vocabulary, transform = model\n",
    "    sentence = json.loads(data)\n",
    "    result = predict_sentiment(net, mx.cpu(), transform, sentence)\n",
    "    response_body = json.dumps(result)\n",
    "    return response_body, output_content_type\n",
    "\n",
    "\n",
    "def predict_sentiment(net, ctx, transform, sentence):\n",
    "    ctx = ctx[0] if isinstance(ctx, list) else ctx\n",
    "    inputs, seq_len, token_types = transform([sentence])\n",
    "    inputs = mx.nd.array([inputs], ctx=ctx)\n",
    "    token_types = mx.nd.array([token_types], ctx=ctx)\n",
    "    seq_len = mx.nd.array([seq_len], ctx=ctx)\n",
    "    out = net(inputs, token_types, seq_len)\n",
    "    label = mx.nd.argmax(out, axis=1)\n",
    "    return 'positive' if label.asscalar() == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Build a Docker Container for Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's prepare a docker container with all the dependencies required for model inference. Here we build a docker container based on the SageMaker MXNet inference container, and you can find the list of all available inference containers at https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html\n",
    "\n",
    "Here we use local mode for demonstration purpose. To deploy on actual instances, you need to login into AWS elastic container registry (ECR) service, and push the container to ECR. \n",
    "\n",
    "```\n",
    "docker build -t $YOUR_EDR_DOCKER_TAG . -f Dockerfile\n",
    "$(aws ecr get-login --no-include-email --region $YOUR_REGION)\n",
    "docker push $YOUR_EDR_DOCKER_TAG\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "ARG REGION\n",
    "FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/mxnet-inference:1.4.1-gpu-py3\n",
    "\n",
    "RUN pip install --upgrade --user --pre 'mxnet-mkl' 'https://github.com/dmlc/gluon-nlp/tarball/v0.9.x'\n",
    "\n",
    "RUN pip list | grep mxnet\n",
    "\n",
    "COPY *.py /opt/ml/model/code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  845.1MB\n",
      "Step 1/5 : ARG REGION\n",
      "Step 2/5 : FROM 763104351884.dkr.ecr.$REGION.amazonaws.com/mxnet-inference:1.4.1-gpu-py3\n",
      " ---> d9dd4dcfe0c2\n",
      "Step 3/5 : RUN pip install --upgrade --user --pre 'mxnet-mkl' 'https://github.com/dmlc/gluon-nlp/tarball/v0.9.x'\n",
      " ---> Running in 6429cf000b5e\n",
      "Collecting https://github.com/dmlc/gluon-nlp/tarball/v0.9.x\n",
      "  Downloading https://github.com/dmlc/gluon-nlp/tarball/v0.9.x (2.4MB)\n",
      "Collecting mxnet-mkl\n",
      "  Downloading https://files.pythonhosted.org/packages/64/72/c5566aabde6ee0bda1f09d026603169a717dbd9f26f6be85ee2b4ed2cf03/mxnet_mkl-1.6.0b20191025-py2.py3-none-manylinux1_x86_64.whl (64.9MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/site-packages (from gluonnlp==0.9.0.dev0) (1.14.6)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.6/site-packages (from mxnet-mkl) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/site-packages (from mxnet-mkl) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-mkl) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-mkl) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-mkl) (1.25.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet-mkl) (2019.6.16)\n",
      "\u001b[91mERROR: mxnet-mkl 1.6.0b20191025 has requirement numpy<2.0.0,>1.16.0, but you'll have numpy 1.14.6 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: mxnet-mkl, gluonnlp\n",
      "  Running setup.py install for gluonnlp: started\n",
      "    Running setup.py install for gluonnlp: finished with status 'done'\n",
      "Successfully installed gluonnlp-0.9.0.dev0 mxnet-mkl-1.6.0b20191025\n",
      "\u001b[91mWARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 6429cf000b5e\n",
      " ---> dea03037d677\n",
      "Step 4/5 : RUN pip list | grep mxnet\n",
      " ---> Running in a9f559d1ba79\n",
      "\u001b[91mWARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[0mkeras-mxnet                       2.2.4.1       \n",
      "mxnet-cu100mkl                    1.4.1         \n",
      "mxnet-mkl                         1.6.0b20191025\n",
      "mxnet-model-server                1.0.4         \n",
      "sagemaker-mxnet-serving-container 1.0.0         \n",
      "Removing intermediate container a9f559d1ba79\n",
      " ---> 40fb2112aeb7\n",
      "Step 5/5 : COPY *.py /opt/ml/model/code/\n",
      " ---> ec76059e75fe\n",
      "Successfully built ec76059e75fe\n",
      "Successfully tagged my-docker:inference\n"
     ]
    }
   ],
   "source": [
    "!export REGION=$(wget -qO- http://169.254.169.254/latest/meta-data/placement/availability-zone) &&\\\n",
    " docker build --no-cache --build-arg REGION=${REGION::-1} -t my-docker:inference . -f Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use SageMaker SDK to Deploy the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We create a MXNet model which can be deployed later, by specifying the docker image, and entry point for the inference code. If serve.py does not work, use dummy_hosting_module.py for debugging purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.mxnet.model import MXNetModel\n",
    "sagemaker_model = MXNetModel(model_data='file:///home/ec2-user/SageMaker/reinvent19-gluonnlp/tutorial/model.tar.gz',\n",
    "                             image='my-docker:inference', # docker images\n",
    "                             role=sagemaker.get_execution_role(), \n",
    "                             py_version='py3',            # python version\n",
    "                             entry_point='serve.py',\n",
    "                             source_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We use 'local' mode to test our deployment code, where the inference happens on the current instance.\n",
    "If you are ready to deploy the model on a new instance, change the `instance_type` argument to values such as `ml.c4.xlarge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpftop30rv_algo-1-f5zzv_1\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,714 [INFO ] main com.amazonaws.ml.mms.ModelServer - \n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m MMS Home: /usr/local/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Current directory: /\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Temp directory: /home/model-server/tmp\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Number of GPUs: 0\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Number of CPUs: 8\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Max heap size: 13646 M\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Python executable: /usr/local/bin/python3.6\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Config file: /etc/sagemaker-mms.properties\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Inference address: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Management address: http://127.0.0.1:8081\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Model Store: /.sagemaker/mms/models\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Initial Models: ALL\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Log dir: /logs\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Metrics dir: /logs\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Netty threads: 0\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Netty client threads: 0\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Default workers per model: 8\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Blacklist Regex: N/A\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Maximum Response Size: 6553500\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Maximum Request Size: 6553500\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,778 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,800 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,977 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9006\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,978 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]80\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,978 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,979 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,983 [INFO ] W-9006-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9006\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,991 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9005\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,992 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]77\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,992 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,993 [INFO ] W-9005-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9005\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:10,993 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,001 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,001 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9001\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,001 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]78\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,002 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,002 [INFO ] W-9001-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9001\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,002 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,003 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]76\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,003 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,003 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,004 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9004\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,004 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,004 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]81\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,007 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,007 [INFO ] W-9004-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9004\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,008 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,014 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,014 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Management server with: EpollServerSocketChannel.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,016 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9002\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,016 [INFO ] W-9004-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9004.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,016 [INFO ] W-9006-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9006.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,017 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]83\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,017 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,018 [INFO ] W-9001-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9001.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,018 [INFO ] W-9005-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9005.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,018 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9002\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,018 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,019 [INFO ] main com.amazonaws.ml.mms.ModelServer - Management API bind to: http://127.0.0.1:8081\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,019 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,021 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9007\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,021 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]82\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,024 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9003\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,024 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID]79\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,024 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,024 [INFO ] W-9007-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9007\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,024 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,024 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MXNet worker started.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m Model server started.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,025 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.6.8\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,024 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9003\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,026 [INFO ] W-9002-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9002.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,026 [INFO ] W-9007-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9007.\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:11,026 [INFO ] W-9003-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9003.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:14,017 [INFO ] W-9006-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2960\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:14,027 [INFO ] W-9002-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2979\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:14,045 [INFO ] W-9001-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2999\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:14,063 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3011\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:14,065 [INFO ] W-9004-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 2997\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:14,072 [INFO ] W-9007-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3027\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:14,078 [INFO ] W-9003-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3022\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:14,122 [INFO ] W-9005-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3070\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:16,074 [INFO ] pool-1-thread-9 ACCESS_LOG - /172.18.0.1:35840 \"GET /ping HTTP/1.1\" 200 13\n",
      "!"
     ]
    }
   ],
   "source": [
    "# Here we use 'local' mode for testing, for real instances use c5.2xlarge, p2.xlarge, etc\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=1, instance_type='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:27,000 [WARN ] W-9006-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - /root/.local/lib/python3.6/site-packages/mxnet/gluon/block.py:1366: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:27,000 [WARN ] W-9006-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - \tdata0: None\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:27,000 [WARN ] W-9006-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   input_sym_arg_type = in_param.infer_type()[0]\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:28,077 [INFO ] W-9006-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1100\n",
      "\u001b[36malgo-1-f5zzv_1  |\u001b[0m 2019-12-04 04:55:28,077 [INFO ] W-9006-model ACCESS_LOG - /172.18.0.1:35848 \"POST /invocations HTTP/1.1\" 200 1104\n",
      "\n",
      "Prediction output: positive\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = predictor.predict('The model is deployed. Great!')  \n",
    "print('\\nPrediction output: {}\\n\\n'.format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clean Up\n",
    "\n",
    "Remove the endpoint after we are done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Resources\n",
    "- Amazon SageMaker https://aws.amazon.com/sagemaker/\n",
    "- Amazon SageMaker Python SDK https://sagemaker.readthedocs.io/\n",
    "- GluonNLP http://gluon-nlp.mxnet.io/\n",
    "- GluonCV http://gluon-cv.mxnet.io/\n",
    "- GluonTS https://gluon-ts.mxnet.io/\n",
    "- Dive into Deep Learning http://d2l.ai/\n",
    "- MXNet Forum https://discuss.mxnet.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "For more fine-tuning scripts, visit the [BERT model zoo webpage](http://gluon-nlp.mxnet.io/model_zoo/bert/index.html).\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Devlin, Jacob, et al. \"Bert:\n",
    "Pre-training of deep\n",
    "bidirectional transformers for language understanding.\"\n",
    "arXiv preprint\n",
    "arXiv:1810.04805 (2018).\n",
    "\n",
    "[2] Dolan, William B., and Chris\n",
    "Brockett.\n",
    "\"Automatically constructing a corpus of sentential paraphrases.\"\n",
    "Proceedings of\n",
    "the Third International Workshop on Paraphrasing (IWP2005). 2005.\n",
    "\n",
    "[3] Peters,\n",
    "Matthew E., et al. \"Deep contextualized word representations.\" arXiv\n",
    "preprint\n",
    "arXiv:1802.05365 (2018).\n",
    "\n",
    "[4] Hendrycks, Dan, and Kevin Gimpel. \"Gaussian error linear units (gelus).\" arXiv preprint arXiv:1606.08415 (2016)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "kernelspec": {"display_name": "conda_mxnet_p36","language": "python", "name": "conda_mxnet_p36"},"language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
